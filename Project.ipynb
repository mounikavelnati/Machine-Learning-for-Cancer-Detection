{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1393608b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 33)\n",
      "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
      "0    842302         M        17.99         10.38          122.80     1001.0   \n",
      "1    842517         M        20.57         17.77          132.90     1326.0   \n",
      "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
      "3  84348301         M        11.42         20.38           77.58      386.1   \n",
      "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
      "\n",
      "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "0          0.11840           0.27760          0.3001              0.14710   \n",
      "1          0.08474           0.07864          0.0869              0.07017   \n",
      "2          0.10960           0.15990          0.1974              0.12790   \n",
      "3          0.14250           0.28390          0.2414              0.10520   \n",
      "4          0.10030           0.13280          0.1980              0.10430   \n",
      "\n",
      "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
      "0  ...          17.33           184.60      2019.0            0.1622   \n",
      "1  ...          23.41           158.80      1956.0            0.1238   \n",
      "2  ...          25.53           152.50      1709.0            0.1444   \n",
      "3  ...          26.50            98.87       567.7            0.2098   \n",
      "4  ...          16.67           152.20      1575.0            0.1374   \n",
      "\n",
      "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
      "0             0.6656           0.7119                0.2654          0.4601   \n",
      "1             0.1866           0.2416                0.1860          0.2750   \n",
      "2             0.4245           0.4504                0.2430          0.3613   \n",
      "3             0.8663           0.6869                0.2575          0.6638   \n",
      "4             0.2050           0.4000                0.1625          0.2364   \n",
      "\n",
      "   fractal_dimension_worst  Unnamed: 32  \n",
      "0                  0.11890          NaN  \n",
      "1                  0.08902          NaN  \n",
      "2                  0.08758          NaN  \n",
      "3                  0.17300          NaN  \n",
      "4                  0.07678          NaN  \n",
      "\n",
      "[5 rows x 33 columns]\n",
      "id                           0\n",
      "diagnosis                    0\n",
      "radius_mean                  0\n",
      "texture_mean                 0\n",
      "perimeter_mean               0\n",
      "area_mean                    0\n",
      "smoothness_mean              0\n",
      "compactness_mean             0\n",
      "concavity_mean               0\n",
      "concave points_mean          0\n",
      "symmetry_mean                0\n",
      "fractal_dimension_mean       0\n",
      "radius_se                    0\n",
      "texture_se                   0\n",
      "perimeter_se                 0\n",
      "area_se                      0\n",
      "smoothness_se                0\n",
      "compactness_se               0\n",
      "concavity_se                 0\n",
      "concave points_se            0\n",
      "symmetry_se                  0\n",
      "fractal_dimension_se         0\n",
      "radius_worst                 0\n",
      "texture_worst                0\n",
      "perimeter_worst              0\n",
      "area_worst                   0\n",
      "smoothness_worst             0\n",
      "compactness_worst            0\n",
      "concavity_worst              0\n",
      "concave points_worst         0\n",
      "symmetry_worst               0\n",
      "fractal_dimension_worst      0\n",
      "Unnamed: 32                569\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from flask import * # flask is a web framework\n",
    "import numpy as np #Numerical Python for processing the arrays \n",
    "from sklearn.decomposition import PCA # Principal Component Analysis for dimensionality reduction\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns # data visualization library  \n",
    "import matplotlib.pyplot as plt # to plot the data (Bar Graph, Histogram...)\n",
    "\n",
    "np.random.seed(0)\n",
    "data = pd.read_csv('C:/Users/Vara/Downloads/data.csv') \n",
    "\n",
    "#It prints number of rows and columns in the dataset\n",
    "print (data.shape)\n",
    "\n",
    "# Print the 5 first rows of dataset\n",
    "print(data.head()) \n",
    "#print(data.tail()) here the last 5 dataset will be printed\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0104c5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   fractal_dimension_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy the list of coulmn names\n",
    "col = data.columns      \n",
    "\n",
    "# Diagnosis includes our labels and x includes our features\n",
    "y = data.diagnosis    # M or B \n",
    "\n",
    "# Drop the last column, ID and diagnosis\n",
    "df=data.drop(['Unnamed: 32','id'],axis=1)\n",
    "x = df.drop('diagnosis',axis = 1 )\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7f4ce31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Benign:  357\n",
      "Number of Malignant :  212\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vara\\anaconda3\\lib\\site-packages\\seaborn\\_decorators.py:36: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = sns.countplot(y,label=\"Count\")\n",
    "B, M = y.value_counts()\n",
    "print('Number of Benign: ',B)\n",
    "print('Number of Malignant : ',M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a36d2f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     radius_mean  texture_mean  perimeter_mean  area_mean  smoothness_mean  \\\n",
      "0          17.99         10.38          122.80     1001.0          0.11840   \n",
      "1          20.57         17.77          132.90     1326.0          0.08474   \n",
      "2          19.69         21.25          130.00     1203.0          0.10960   \n",
      "3          11.42         20.38           77.58      386.1          0.14250   \n",
      "4          20.29         14.34          135.10     1297.0          0.10030   \n",
      "..           ...           ...             ...        ...              ...   \n",
      "564        21.56         22.39          142.00     1479.0          0.11100   \n",
      "565        20.13         28.25          131.20     1261.0          0.09780   \n",
      "566        16.60         28.08          108.30      858.1          0.08455   \n",
      "567        20.60         29.33          140.10     1265.0          0.11780   \n",
      "568         7.76         24.54           47.92      181.0          0.05263   \n",
      "\n",
      "     compactness_mean  concavity_mean  concave points_mean  symmetry_mean  \\\n",
      "0             0.27760         0.30010              0.14710         0.2419   \n",
      "1             0.07864         0.08690              0.07017         0.1812   \n",
      "2             0.15990         0.19740              0.12790         0.2069   \n",
      "3             0.28390         0.24140              0.10520         0.2597   \n",
      "4             0.13280         0.19800              0.10430         0.1809   \n",
      "..                ...             ...                  ...            ...   \n",
      "564           0.11590         0.24390              0.13890         0.1726   \n",
      "565           0.10340         0.14400              0.09791         0.1752   \n",
      "566           0.10230         0.09251              0.05302         0.1590   \n",
      "567           0.27700         0.35140              0.15200         0.2397   \n",
      "568           0.04362         0.00000              0.00000         0.1587   \n",
      "\n",
      "     fractal_dimension_mean  ...  texture_worst  perimeter_worst  area_worst  \\\n",
      "0                   0.07871  ...          17.33           184.60      2019.0   \n",
      "1                   0.05667  ...          23.41           158.80      1956.0   \n",
      "2                   0.05999  ...          25.53           152.50      1709.0   \n",
      "3                   0.09744  ...          26.50            98.87       567.7   \n",
      "4                   0.05883  ...          16.67           152.20      1575.0   \n",
      "..                      ...  ...            ...              ...         ...   \n",
      "564                 0.05623  ...          26.40           166.10      2027.0   \n",
      "565                 0.05533  ...          38.25           155.00      1731.0   \n",
      "566                 0.05648  ...          34.12           126.70      1124.0   \n",
      "567                 0.07016  ...          39.42           184.60      1821.0   \n",
      "568                 0.05884  ...          30.37            59.16       268.6   \n",
      "\n",
      "     smoothness_worst  compactness_worst  concavity_worst  \\\n",
      "0             0.16220            0.66560           0.7119   \n",
      "1             0.12380            0.18660           0.2416   \n",
      "2             0.14440            0.42450           0.4504   \n",
      "3             0.20980            0.86630           0.6869   \n",
      "4             0.13740            0.20500           0.4000   \n",
      "..                ...                ...              ...   \n",
      "564           0.14100            0.21130           0.4107   \n",
      "565           0.11660            0.19220           0.3215   \n",
      "566           0.11390            0.30940           0.3403   \n",
      "567           0.16500            0.86810           0.9387   \n",
      "568           0.08996            0.06444           0.0000   \n",
      "\n",
      "     concave points_worst  symmetry_worst  fractal_dimension_worst  \\\n",
      "0                  0.2654          0.4601                  0.11890   \n",
      "1                  0.1860          0.2750                  0.08902   \n",
      "2                  0.2430          0.3613                  0.08758   \n",
      "3                  0.2575          0.6638                  0.17300   \n",
      "4                  0.1625          0.2364                  0.07678   \n",
      "..                    ...             ...                      ...   \n",
      "564                0.2216          0.2060                  0.07115   \n",
      "565                0.1628          0.2572                  0.06637   \n",
      "566                0.1418          0.2218                  0.07820   \n",
      "567                0.2650          0.4087                  0.12400   \n",
      "568                0.0000          0.2871                  0.07039   \n",
      "\n",
      "     diagnosis_M  \n",
      "0              1  \n",
      "1              1  \n",
      "2              1  \n",
      "3              1  \n",
      "4              1  \n",
      "..           ...  \n",
      "564            1  \n",
      "565            1  \n",
      "566            1  \n",
      "567            1  \n",
      "568            0  \n",
      "\n",
      "[569 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "y_df= pd.get_dummies(y,drop_first=True) # dropping the column called diagnosis and having a columns of 0 and 1\n",
    "y_df.head()\n",
    "y_df=y_df['M']\n",
    "prueba=pd.get_dummies(df,'diagnosis')\n",
    "print(prueba.drop('diagnosis_B',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f0aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       radius_mean  texture_mean  perimeter_mean    area_mean  \\\n",
      "count   569.000000    569.000000      569.000000   569.000000   \n",
      "mean     14.127292     19.289649       91.969033   654.889104   \n",
      "std       3.524049      4.301036       24.298981   351.914129   \n",
      "min       6.981000      9.710000       43.790000   143.500000   \n",
      "25%      11.700000     16.170000       75.170000   420.300000   \n",
      "50%      13.370000     18.840000       86.240000   551.100000   \n",
      "75%      15.780000     21.800000      104.100000   782.700000   \n",
      "max      28.110000     39.280000      188.500000  2501.000000   \n",
      "\n",
      "       smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
      "count       569.000000        569.000000      569.000000           569.000000   \n",
      "mean          0.096360          0.104341        0.088799             0.048919   \n",
      "std           0.014064          0.052813        0.079720             0.038803   \n",
      "min           0.052630          0.019380        0.000000             0.000000   \n",
      "25%           0.086370          0.064920        0.029560             0.020310   \n",
      "50%           0.095870          0.092630        0.061540             0.033500   \n",
      "75%           0.105300          0.130400        0.130700             0.074000   \n",
      "max           0.163400          0.345400        0.426800             0.201200   \n",
      "\n",
      "       symmetry_mean  fractal_dimension_mean  ...  radius_worst  \\\n",
      "count     569.000000              569.000000  ...    569.000000   \n",
      "mean        0.181162                0.062798  ...     16.269190   \n",
      "std         0.027414                0.007060  ...      4.833242   \n",
      "min         0.106000                0.049960  ...      7.930000   \n",
      "25%         0.161900                0.057700  ...     13.010000   \n",
      "50%         0.179200                0.061540  ...     14.970000   \n",
      "75%         0.195700                0.066120  ...     18.790000   \n",
      "max         0.304000                0.097440  ...     36.040000   \n",
      "\n",
      "       texture_worst  perimeter_worst   area_worst  smoothness_worst  \\\n",
      "count     569.000000       569.000000   569.000000        569.000000   \n",
      "mean       25.677223       107.261213   880.583128          0.132369   \n",
      "std         6.146258        33.602542   569.356993          0.022832   \n",
      "min        12.020000        50.410000   185.200000          0.071170   \n",
      "25%        21.080000        84.110000   515.300000          0.116600   \n",
      "50%        25.410000        97.660000   686.500000          0.131300   \n",
      "75%        29.720000       125.400000  1084.000000          0.146000   \n",
      "max        49.540000       251.200000  4254.000000          0.222600   \n",
      "\n",
      "       compactness_worst  concavity_worst  concave points_worst  \\\n",
      "count         569.000000       569.000000            569.000000   \n",
      "mean            0.254265         0.272188              0.114606   \n",
      "std             0.157336         0.208624              0.065732   \n",
      "min             0.027290         0.000000              0.000000   \n",
      "25%             0.147200         0.114500              0.064930   \n",
      "50%             0.211900         0.226700              0.099930   \n",
      "75%             0.339100         0.382900              0.161400   \n",
      "max             1.058000         1.252000              0.291000   \n",
      "\n",
      "       symmetry_worst  fractal_dimension_worst  \n",
      "count      569.000000               569.000000  \n",
      "mean         0.290076                 0.083946  \n",
      "std          0.061867                 0.018061  \n",
      "min          0.156500                 0.055040  \n",
      "25%          0.250400                 0.071460  \n",
      "50%          0.282200                 0.080040  \n",
      "75%          0.317900                 0.092080  \n",
      "max          0.663800                 0.207500  \n",
      "\n",
      "[8 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(x.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7392bd7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count of Malignant in train data of 80% is  165\n",
      "count of Benign in train data of 80% is  290\n",
      "count of Malignant in test data of 20% is  47\n",
      "count of Benign in test data of 20% is  67\n",
      "LogisticRegression(max_iter=1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vara\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "df_train, df_test = train_test_split(df, test_size = 0.2)\n",
    "x_train=df_train.drop('diagnosis',axis=1)\n",
    "x_test=df_test.drop('diagnosis',axis=1)\n",
    "y_train=df_train['diagnosis']\n",
    "y_test=df_test['diagnosis']\n",
    "train_l=[]\n",
    "for item in y_train:\n",
    "    train_l.append(item)\n",
    "y_train_Mcount=train_l.count('M')\n",
    "print(\"count of Malignant in train data of 80% is \",y_train_Mcount)\n",
    "y_train_Bcount=train_l.count('B')\n",
    "print(\"count of Benign in train data of 80% is \",y_train_Bcount)\n",
    "train_ourn=y_train_Mcount+y_train_Bcount\n",
    "test_l=[]\n",
    "for item in y_test:\n",
    "    test_l.append(item)\n",
    "y_test_Mcount=test_l.count('M')\n",
    "print(\"count of Malignant in test data of 20% is \",y_test_Mcount)\n",
    "y_test_Bcount=test_l.count('B')\n",
    "print(\"count of Benign in test data of 20% is \",y_test_Bcount)\n",
    "test_ourn=y_test_Mcount+y_test_Bcount\n",
    "#Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "#Create the model\n",
    "modelo_rl= LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "#Fit the model\n",
    "print(modelo_rl.fit(X=x_train,y=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "057f552c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "True Positive of Test data :  46\n",
      "False Positive of Test data :  4\n",
      "True Negative of Test data :  1\n",
      "False Negative of Test data :  63 \n",
      "\n",
      "TRAIN DATA\n",
      "True Positive of Train data :  154\n",
      "False Positive of Train data :  8\n",
      "True Negative of Train data :  11\n",
      "False Negative of Train data :  282 \n",
      "\n",
      "Test data accuracy :  0.9561\n",
      "Test data sensitivity :  0.9787\n",
      "Test data specificity :  0.9844\n",
      "Test data f1-score :  0.9787\n",
      "Train data accuracy :  0.9582\n",
      "Train data sensitivity :  0.9333\n",
      "Train data specificity :  0.9625\n",
      "Train data f1-score :  0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.98      0.94      0.96        67\n",
      "           M       0.92      0.98      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.97      0.97       290\n",
      "           M       0.95      0.93      0.94       165\n",
      "\n",
      "    accuracy                           0.96       455\n",
      "   macro avg       0.96      0.95      0.95       455\n",
      "weighted avg       0.96      0.96      0.96       455\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction\n",
    "train_prediction_rl = modelo_rl.predict(x_train)\n",
    "train_countBB00=train_countMB10=train_countBM01=train_countMM11=0\n",
    "test_prediction_rl = modelo_rl.predict(x_test)\n",
    "test_countBB00=test_countMB10=test_countBM01=test_countMM11=0\n",
    "for i in range(train_ourn):\n",
    "    if(train_l[i]=='B' and train_prediction_rl[i]=='B'):\n",
    "        train_countBB00+=1\n",
    "    elif(train_l[i]=='M' and train_prediction_rl[i]=='B'):\n",
    "        train_countMB10+=1\n",
    "    elif(train_l[i]=='B' and train_prediction_rl[i]=='M'):\n",
    "        train_countBM01+=1\n",
    "    else:\n",
    "        train_countMM11+=1\n",
    "for i in range(test_ourn):\n",
    "    if(test_l[i]=='B' and test_prediction_rl[i]=='B'):\n",
    "        test_countBB00+=1\n",
    "    elif(test_l[i]=='M' and test_prediction_rl[i]=='B'):\n",
    "        test_countMB10+=1\n",
    "    elif(test_l[i]=='B' and test_prediction_rl[i]=='M'):\n",
    "        test_countBM01+=1\n",
    "    else:\n",
    "        test_countMM11+=1\n",
    "#Results:\n",
    "print(\"TEST DATA\")\n",
    "print(\"True Positive of Test data : \",test_countMM11)\n",
    "print(\"False Positive of Test data : \",test_countBM01)\n",
    "print(\"True Negative of Test data : \",test_countMB10)\n",
    "print(\"False Negative of Test data : \",test_countBB00,\"\\n\")\n",
    "\n",
    "print(\"TRAIN DATA\")\n",
    "print(\"True Positive of Train data : \",train_countMM11)\n",
    "print(\"False Positive of Train data : \",train_countBM01)\n",
    "print(\"True Negative of Train data : \",train_countMB10)\n",
    "print(\"False Negative of Train data : \",train_countBB00,\"\\n\")\n",
    "test_acc=(test_countMM11+test_countBB00)/(test_countMM11+test_countMB10+test_countBB00+test_countBM01)\n",
    "test_sens=test_recall=test_countMM11/(test_countMM11+test_countMB10)\n",
    "test_spec=test_countBB00/(test_countMB10+test_countBB00)\n",
    "test_prec=test_countMM11/(test_countMM11+test_countMB10)\n",
    "test_f1=(2*test_prec*test_recall)/(test_prec+test_recall)\n",
    "print(\"Test data accuracy : \",round(test_acc,4))\n",
    "print(\"Test data sensitivity : \",round(test_sens,4))\n",
    "print(\"Test data specificity : \",round(test_spec,4))\n",
    "print(\"Test data f1-score : \",round(test_f1,4))\n",
    "\n",
    "train_acc=(train_countMM11+train_countBB00)/(train_countMM11+train_countMB10+train_countBB00+train_countBM01)\n",
    "train_sens=train_recall=train_countMM11/(train_countMM11+train_countMB10)\n",
    "train_spec=train_countBB00/(train_countMB10+train_countBB00)\n",
    "train_prec=train_countMM11/(train_countMM11+train_countMB10)\n",
    "train_f1=(2*train_prec*train_recall)/(train_prec+train_recall)\n",
    "print(\"Train data accuracy : \",round(train_acc,4))\n",
    "print(\"Train data sensitivity : \",round(train_sens,4))\n",
    "print(\"Train data specificity : \",round(train_spec,4))\n",
    "print(\"Train data f1-score : \",round(train_f1,4))\n",
    "\n",
    "#Clasification report\n",
    "test_results_rl=metrics.classification_report(y_true=y_test, y_pred=test_prediction_rl)\n",
    "print(test_results_rl,\"\\n\")\n",
    "\n",
    "train_results_rl=metrics.classification_report(y_true=y_train,y_pred=train_prediction_rl)\n",
    "print(train_results_rl)\n",
    "\n",
    "#Confusion matrix\n",
    "test_cm_rl=metrics.confusion_matrix(y_true=y_test, y_pred=test_prediction_rl)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(test_cm_rl, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n",
    "\n",
    "train_cm_rl=metrics.confusion_matrix(y_true=y_train, y_pred=train_prediction_rl)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(train_cm_rl, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed4ab57c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GradientBoostingClassifier()\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Create the model\n",
    "modelo_gd= GradientBoostingClassifier()\n",
    "# Fit the model\n",
    "print(modelo_gd.fit(X=x_train,y=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e0211683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "True Positive of Test data :  45\n",
      "False Positive of Test data :  3\n",
      "True Negative of Test data :  2\n",
      "False Negative of Test data :  64 \n",
      "\n",
      "TRAIN DATA\n",
      "True Positive of Train data :  165\n",
      "False Positive of Train data :  0\n",
      "True Negative of Train data :  0\n",
      "False Negative of Train data :  290 \n",
      "\n",
      "Test data accuracy :  0.9561\n",
      "Test data sensitivity :  0.9574\n",
      "Test data specificity :  0.9697\n",
      "Test data f1-score :  0.9574\n",
      "\n",
      "Train data accuracy :  1.0\n",
      "Train data sensitivity :  1.0\n",
      "Train data specificity :  1.0\n",
      "Train data f1-score :  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      0.96      0.96        67\n",
      "           M       0.94      0.96      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.95       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00       290\n",
      "           M       1.00      1.00      1.00       165\n",
      "\n",
      "    accuracy                           1.00       455\n",
      "   macro avg       1.00      1.00      1.00       455\n",
      "weighted avg       1.00      1.00      1.00       455\n",
      " \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Prediction\n",
    "train_prediction_gd = modelo_gd.predict(x_train)\n",
    "gdtrain_countBB00=gdtrain_countMB10=gdtrain_countBM01=gdtrain_countMM11=0\n",
    "test_prediction_gd = modelo_gd.predict(x_test)\n",
    "gdtest_countBB00=gdtest_countMB10=gdtest_countBM01=gdtest_countMM11=0\n",
    "for i in range(train_ourn):\n",
    "    if(train_l[i]=='B' and train_prediction_gd[i]=='B'):\n",
    "        gdtrain_countBB00+=1\n",
    "    elif(train_l[i]=='M' and train_prediction_gd[i]=='B'):\n",
    "        gdtrain_countMB10+=1\n",
    "    elif(train_l[i]=='B' and train_prediction_gd[i]=='M'):\n",
    "        gdtrain_countBM01+=1\n",
    "    else:\n",
    "        gdtrain_countMM11+=1\n",
    "for i in range(test_ourn):\n",
    "    if(test_l[i]=='B' and test_prediction_gd[i]=='B'):\n",
    "        gdtest_countBB00+=1\n",
    "    elif(test_l[i]=='M' and test_prediction_gd[i]=='B'):\n",
    "        gdtest_countMB10+=1\n",
    "    elif(test_l[i]=='B' and test_prediction_gd[i]=='M'):\n",
    "        gdtest_countBM01+=1\n",
    "    else:\n",
    "        gdtest_countMM11+=1\n",
    "#Results:\n",
    "print(\"TEST DATA\")\n",
    "print(\"True Positive of Test data : \",gdtest_countMM11)\n",
    "print(\"False Positive of Test data : \",gdtest_countBM01)\n",
    "print(\"True Negative of Test data : \",gdtest_countMB10)\n",
    "print(\"False Negative of Test data : \",gdtest_countBB00,\"\\n\")\n",
    "\n",
    "print(\"TRAIN DATA\")\n",
    "print(\"True Positive of Train data : \",gdtrain_countMM11)\n",
    "print(\"False Positive of Train data : \",gdtrain_countBM01)\n",
    "print(\"True Negative of Train data : \",gdtrain_countMB10)\n",
    "print(\"False Negative of Train data : \",gdtrain_countBB00,\"\\n\")\n",
    "\n",
    "gdtest_acc=(gdtest_countMM11+gdtest_countBB00)/(gdtest_countMM11+gdtest_countMB10+gdtest_countBB00+gdtest_countBM01)\n",
    "gdtest_sens=gdtest_recall=gdtest_countMM11/(gdtest_countMM11+gdtest_countMB10)\n",
    "gdtest_spec=gdtest_countBB00/(gdtest_countMB10+gdtest_countBB00)\n",
    "gdtest_prec=gdtest_countMM11/(gdtest_countMM11+gdtest_countMB10)\n",
    "gdtest_f1=(2*gdtest_prec*gdtest_recall)/(gdtest_prec+gdtest_recall)\n",
    "print(\"Test data accuracy : \",round(gdtest_acc,4))\n",
    "print(\"Test data sensitivity : \",round(gdtest_sens,4))\n",
    "print(\"Test data specificity : \",round(gdtest_spec,4))\n",
    "print(\"Test data f1-score : \",round(gdtest_f1,4))\n",
    "print(\"\")\n",
    "\n",
    "gdtrain_acc=(gdtrain_countMM11+gdtrain_countBB00)/(gdtrain_countMM11+gdtrain_countMB10+gdtrain_countBB00+gdtrain_countBM01)\n",
    "gdtrain_sens=gdtrain_recall=gdtrain_countMM11/(gdtrain_countMM11+gdtrain_countMB10)\n",
    "gdtrain_spec=gdtrain_countBB00/(gdtrain_countMB10+gdtrain_countBB00)\n",
    "gdtrain_prec=gdtrain_countMM11/(gdtrain_countMM11+gdtrain_countMB10)\n",
    "gdtrain_f1=(2*gdtrain_prec*gdtrain_recall)/(gdtrain_prec+gdtrain_recall)\n",
    "print(\"Train data accuracy : \",round(gdtrain_acc,4))\n",
    "print(\"Train data sensitivity : \",round(gdtrain_sens,4))\n",
    "print(\"Train data specificity : \",round(gdtrain_spec,4))\n",
    "print(\"Train data f1-score : \",round(gdtrain_f1,4))\n",
    "\n",
    "#Clasification report\n",
    "test_results_gd=metrics.classification_report(y_true=y_test, y_pred=test_prediction_gd)\n",
    "print(test_results_gd,\"\\n\")\n",
    "\n",
    "train_results_gd=metrics.classification_report(y_true=y_train, y_pred=train_prediction_gd)\n",
    "print(train_results_gd,\"\\n\")\n",
    "\n",
    "#Confusion matrix\n",
    "test_cm_gd=metrics.confusion_matrix(y_true=y_test, y_pred=test_prediction_gd)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(test_cm_gd, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n",
    "\n",
    "train_cm_gd=metrics.confusion_matrix(y_true=y_train, y_pred=train_prediction_gd)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(train_cm_gd, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f883dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier()\n"
     ]
    }
   ],
   "source": [
    "#Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#Create the model\n",
    "modelo_rf= RandomForestClassifier()\n",
    "#Fit the model\n",
    "print(modelo_rf.fit(X=x_train,y=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4fd0c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "True Positive of Test data :  45\n",
      "False Positive of Test data :  2\n",
      "True Negative of Test data :  2\n",
      "False Negative of Test data :  65 \n",
      "\n",
      "TRAIN DATA\n",
      "True Positive of Train data :  165\n",
      "False Positive of Train data :  0\n",
      "True Negative of Train data :  0\n",
      "False Negative of Train data :  290 \n",
      "\n",
      "Test data accuracy :  0.9649\n",
      "Test data sensitivity :  0.9574\n",
      "Test data specificity :  0.9701\n",
      "Test data f1-score :  0.9574\n",
      "Train data accuracy :  1.0\n",
      "Train data sensitivity :  1.0\n",
      "Train data specificity :  1.0\n",
      "Train data f1-score :  1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.97      0.97      0.97        67\n",
      "           M       0.96      0.96      0.96        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.96      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       1.00      1.00      1.00       290\n",
      "           M       1.00      1.00      1.00       165\n",
      "\n",
      "    accuracy                           1.00       455\n",
      "   macro avg       1.00      1.00      1.00       455\n",
      "weighted avg       1.00      1.00      1.00       455\n",
      " \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_prediction_rf = modelo_rf.predict(x_train)\n",
    "rftrain_countBB00=rftrain_countMB10=rftrain_countBM01=rftrain_countMM11=0\n",
    "test_prediction_rf = modelo_rf.predict(x_test)\n",
    "rftest_countBB00=rftest_countMB10=rftest_countBM01=rftest_countMM11=0\n",
    "for i in range(train_ourn):\n",
    "    if(train_l[i]=='B' and train_prediction_rf[i]=='B'):\n",
    "        rftrain_countBB00+=1\n",
    "    elif(train_l[i]=='M' and train_prediction_rf[i]=='B'):\n",
    "        rftrain_countMB10+=1\n",
    "    elif(train_l[i]=='B' and train_prediction_rf[i]=='M'):\n",
    "        rftrain_countBM01+=1\n",
    "    else:\n",
    "        rftrain_countMM11+=1\n",
    "for i in range(test_ourn):\n",
    "    if(test_l[i]=='B' and test_prediction_rf[i]=='B'):\n",
    "        rftest_countBB00+=1\n",
    "    elif(test_l[i]=='M' and test_prediction_rf[i]=='B'):\n",
    "        rftest_countMB10+=1\n",
    "    elif(test_l[i]=='B' and test_prediction_rf[i]=='M'):\n",
    "        rftest_countBM01+=1\n",
    "    else:\n",
    "        rftest_countMM11+=1\n",
    "#Results:\n",
    "print(\"TEST DATA\")\n",
    "print(\"True Positive of Test data : \",rftest_countMM11)\n",
    "print(\"False Positive of Test data : \",rftest_countBM01)\n",
    "print(\"True Negative of Test data : \",rftest_countMB10)\n",
    "print(\"False Negative of Test data : \",rftest_countBB00,\"\\n\")\n",
    "\n",
    "print(\"TRAIN DATA\")\n",
    "print(\"True Positive of Train data : \",rftrain_countMM11)\n",
    "print(\"False Positive of Train data : \",rftrain_countBM01)\n",
    "print(\"True Negative of Train data : \",rftrain_countMB10)\n",
    "print(\"False Negative of Train data : \",rftrain_countBB00,\"\\n\")\n",
    "rftest_acc=(rftest_countMM11+rftest_countBB00)/(rftest_countMM11+rftest_countMB10+rftest_countBB00+rftest_countBM01)\n",
    "rftest_sens=rftest_recall=rftest_countMM11/(rftest_countMM11+rftest_countMB10)\n",
    "rftest_spec=rftest_countBB00/(rftest_countMB10+rftest_countBB00)\n",
    "rftest_prec=rftest_countMM11/(rftest_countMM11+rftest_countMB10)\n",
    "rftest_f1=(2*rftest_prec*rftest_recall)/(rftest_prec+rftest_recall)\n",
    "\n",
    "print(\"Test data accuracy : \",round(rftest_acc,4))\n",
    "print(\"Test data sensitivity : \",round(rftest_sens,4))\n",
    "print(\"Test data specificity : \",round(rftest_spec,4))\n",
    "print(\"Test data f1-score : \",round(rftest_f1,4))\n",
    "\n",
    "rftrain_acc=(rftrain_countMM11+rftrain_countBB00)/(rftrain_countMM11+rftrain_countMB10+rftrain_countBB00+rftrain_countBM01)\n",
    "rftrain_sens=rftrain_recall=rftrain_countMM11/(rftrain_countMM11+rftrain_countMB10)\n",
    "rftrain_spec=rftrain_countBB00/(rftrain_countMB10+rftrain_countBB00)\n",
    "rftrain_prec=rftrain_countMM11/(rftrain_countMM11+rftrain_countMB10)\n",
    "rftrain_f1=(2*rftrain_prec*rftrain_recall)/(rftrain_prec+rftrain_recall)\n",
    "print(\"Train data accuracy : \",round(rftrain_acc,4))\n",
    "print(\"Train data sensitivity : \",round(rftrain_sens,4))\n",
    "print(\"Train data specificity : \",round(rftrain_spec,4))\n",
    "print(\"Train data f1-score : \",round(rftrain_f1,4))\n",
    "\n",
    "#Clasification report\n",
    "test_results_rf=metrics.classification_report(y_true=y_test, y_pred=test_prediction_rf)\n",
    "print(test_results_rf,\"\\n\")\n",
    "\n",
    "train_results_rf=metrics.classification_report(y_true=y_train, y_pred=train_prediction_rf)\n",
    "print(train_results_rf,\"\\n\")\n",
    "\n",
    "#Confusion matrix\n",
    "test_cm_rf=metrics.confusion_matrix(y_true=y_test, y_pred=test_prediction_rf)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(test_cm_rf, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n",
    "\n",
    "train_cm_rf=metrics.confusion_matrix(y_true=y_train, y_pred=train_prediction_rf)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(train_cm_rf, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "073a984a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "#SVM\n",
    "from sklearn.svm import SVC\n",
    "# Create the model\n",
    "modelo_svm= SVC(kernel='linear', C = 1.0)\n",
    "# Fit the model\n",
    "print(modelo_svm.fit(X=x_train,y=y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7b9ed606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST DATA\n",
      "True Positive of Test data :  46\n",
      "False Positive of Test data :  4\n",
      "True Negative of Test data :  1\n",
      "False Negative of Test data :  63 \n",
      "\n",
      "TRAIN DATA\n",
      "True Positive of Train data :  154\n",
      "False Positive of Train data :  5\n",
      "True Negative of Train data :  11\n",
      "False Negative of Train data :  285 \n",
      "\n",
      "Test data accuracy :  0.9561\n",
      "Test data sensitivity :  0.9787\n",
      "Test data specificity :  0.9844\n",
      "Test data f1-score :  0.9787\n",
      "Train data accuracy :  0.9648\n",
      "Train data sensitivity :  0.9333\n",
      "Train data specificity :  0.9628\n",
      "Train data f1-score :  0.9333\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.98      0.94      0.96        67\n",
      "           M       0.92      0.98      0.95        47\n",
      "\n",
      "    accuracy                           0.96       114\n",
      "   macro avg       0.95      0.96      0.96       114\n",
      "weighted avg       0.96      0.96      0.96       114\n",
      " \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.96      0.98      0.97       290\n",
      "           M       0.97      0.93      0.95       165\n",
      "\n",
      "    accuracy                           0.96       455\n",
      "   macro avg       0.97      0.96      0.96       455\n",
      "weighted avg       0.96      0.96      0.96       455\n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n",
      "AxesSubplot(0.125,0.125;0.62x0.755) \n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAUlklEQVR4nO3de3SU5bXH8e8miIuCcgtiCDkIElE4tehS1KqnXqCirSAecVEtB1tsOD0oaG1V6lJbLaWrVdSqtEZREKscrFjQilVoT9VaUbBUiRSJgpIL94tyKZDJPn9koPNCkpmEyUwe8vu43jXvPO9tj9G99vO8N3N3RERC1SrbAYiIHAolMREJmpKYiARNSUxEgqYkJiJBa52BY+j0p0h2WGM22rvx45T/nz0it3ejjpFOmUhi7N34cSYOI2l2RG5vAFq3yc9yJNIYVXvKsx1CRmQkiYlIQKpj2Y6gQZTERCQqVpXtCBpESUxEItyrsx1CgyiJiUhUtZKYiIRMlZiIBE0D+yISNFViIhIy19lJEQmaBvZFJGjqTopI0DSwLyJBUyUmIkHTwL6IBE0D+yISMneNiYlIyDQmJiJBU3dSRIKmSkxEghbbm+0IGkRJTESi1J0UkaCpOykiQQusEtPLc0Ukqro69SkJMyswsz+Z2XIzKzGzCfH2H5lZuZktjU+XJGwz0cxKzWyFmV2U7BiqxEQkwtM7sF8F3OTu75rZUcASM3s1vuw+d78ncWUz6weMBPoD3YEFZnaC13MFrioxEYny6tSnZLtyr3T3d+PznwPLgfrexjwMmOXuu919FVAKDKzvGEpiIhKVxu5kIjM7DjgFWBRvus7M3jOzx82sU7wtH1iTsFkZ9Sc9JTEROUADKjEzKzKzxQlTUW27NLP2wHPADe7+GfAr4HhgAFAJ3Ltv1doiqi9cjYmJSFQDKix3LwaK61vHzI6gJoH9xt3nxLdbl7D8UeDF+NcyoCBh8x5ARX37VyUmIlFpHBMzMwOmAcvdfUpCe17CasOBZfH5ecBIMzvSzHoBhcDb9R1DlZiIRFWl9aGIZwOjgPfNbGm87YfAN8xsADVdxdXAWAB3LzGz2cAH1JzZHFffmUlQEhORA6Xxin13f4Pax7leqmebScCkVI+hJCYiUYFdsa8kJiJRundSRIKmSkxEgqZKTESClt6zk01OSUxEorzeC+SbHSUxEYnSmJiIBE1JTESCpoF9EQlaTG8AF5GQqTspIkFTEhORoGlMTERC5tW6TkxEQqbupIgETWcnRSRoqsREJGhKYmGqXLeBH959Dxs3b6GVGVcMu5hRV17GPz78iLt+8SC79+wlJyeH278/ji/260t55TqGXlXEcf/WA4CT+5/InTdff9B+t332OTfdPpmKtevofmw37r17Ih2OPirTP69FK/3wLT7fvp1YrJqqqirOPOuSg9a5b8pdXDzkAnbu2sWYMTfyt6XLatlTC6EbwMPUOieHH1z/Hfr17cOOHTu5csx4vnz6Kdw7dRrf/fbVnHvW6bz25tvcO3Ua0x/6OQAF+Xk8N+Phevf72MzZnHnaAK4ddSWPzZzNtKdm873/GZOJnyQJBg0ewaZNW2pddvGQCyjs04sT+53DGQNP5eGHJvPlcy7NcITNSGCVWNJXtpnZiWZ2i5n90sweiM+flIngMqlrbmf69e0DQLt2X6B3zwLWbdiEmbF9x04Atu/YyTG5XRq03z+9/leGXTwIgGEXD+KPr/01vYHLIbv00ouY+ZvfArDo7Xfp0LEDxx57TJajyqJqT31qBupNYmZ2CzCLmreVvA28E59/xsxubfrwsqO8ch3LV37Eyf37csuEsdw7dRoXDh/FPQ89xg3/fU3Cemu54ppxXDPuByypo/uxactWuuZ2BmoS5eat2zLxEySBuzP/pWdY9NZ8rh1z9UHL87sfS9maf72ftbyskvzux2YyxOYlFkt9agaSdSfHAP3dfW9io5lNAUqAn9W2UfxV5kUAjzzyCN+6fFAaQs2MnTt3ceNtP+GW8WNp364dvyx+kluuL2Lw+efw8sLXuGPy/Tz2wGS6dunEq3OepGOHoyn5x0rGT7yLuU/9mvbt2mX7J8gB/uO8y6isXEfXrl14ef4sVqwo5fU3Fu1fXvN+1ygPbFwonfww605WA91rac+LL6uVuxe7+2nuflpRUdGhxJdRe6uquOG2n/C1r57P4PPOBmDe/AUMis9fdMG5vP/BCgDatGlDxw5HA9D/xEIK8vNY/Wn5Qfvs0qkjGzZuBmDDxs107tghEz9FElRWrgNgw4ZNzJ07n9NPHxBZXlZeSY+Cf/1nnt8jj4r4Ni3S4dSdBG4AFprZfDMrjk8vAwuBCU0eXQa5O3dMvp/ePQsYPfLy/e1dc7vwzt/eB2DRkqX0LMgHYPOWrcTi5fSa8ko+XVNBQX7eQfs975wzmTt/AQBz5y/g/HPPauqfIgm+8IW2tG/fbv/84EFfoaRkRWSdF198hVFXXwHAGQNP5bNtn7F27fqMx9pseHXqUzNQb3fS3V82sxOAgUA+NeNhZcA7yV4tHpq/vVfCCy8vpPD44/jP0eMAmDB2ND++ZTw/e+ARqmIxjmzThjtvHg/AkqXLeOixmeS0ziGnVSvu+MF1+y+duGPy/Vx52SX8+0kncO2oK7np9p8y58U/kNetK1N+clvWfmNL1K1bV3777DQAWrfOYdas3/GHV/6Pou+MAqD40Zm8NH8hQ4ZcwIrlf2Hnrl1ce+33shly9jWTCitVloG+v+/d+HFTH0OawBG5vQFo3SY/y5FIY1TtKT94sC8FO+4YmXJSaHfXrEYdI510nZiIRDWTbmKqlMREJCqw7qSSmIhEHG6XWIhIS5PGSyzMrMDM/mRmy82sxMwmxNs7m9mrZrYy/tkpYZuJZlZqZivM7KJkx1ASE5Go9F4nVgXc5O4nAWcC48ysH3ArsNDdC6m5ZOtWgPiykUB/YAgw1cxy6juAkpiIRKXxtiN3r3T3d+PznwPLqblcaxgwI77aDOCy+PwwYJa773b3VUApNZd41UlJTEQivNpTnsysyMwWJ0x13qJjZscBpwCLgG7uXgk1iQ7Yd8d9PrAmYbOyeFudNLAvIlENODvp7sVAcbL1zKw98Bxwg7t/Vtv9qvtWre0w9e1bSUxEotJ8dtLMjqAmgf3G3efEm9eZWZ67V5pZHrDvPq8yoCBh8x5ABfVQd1JEotJ7dtKAacByd5+SsGgeMDo+PxqYm9A+0syONLNeQCE1jwGrkyoxEYlK78WuZwOjgPfNbGm87YfUPMZrtpmNAT4FRgC4e4mZzQY+oObM5rhk92kriYlIhMfS15109zeofZwL4MI6tpkETEr1GEpiIhKl245EJGSuJCYiQVMSE5GghXX/t5KYiER5VVhZTElMRKLCymFKYiISpYF9EQmbKjERCZkqMREJmyoxEQmZV2U7goZREhORiMDe2KYkJiIHUBITkZCpEhORoCmJiUjQPFbn8++bJSUxEYlQJSYiQfNqVWIiEjBVYiISNHdVYiISMFViIhK0ap2dFJGQaWBfRIKmJCYiQfOwHiemJCYiUarERCRousRCRIIW09lJEQmZKjERCVpoY2Ktsh2AiDQv7qlPyZjZ42a23syWJbT9yMzKzWxpfLokYdlEMys1sxVmdlEq8aoSE5GINFdi04GHgCcPaL/P3e9JbDCzfsBIoD/QHVhgZie4e6y+A6gSE5GIWHWrlKdk3P01YHOKhx4GzHL33e6+CigFBibbSElMRCIa0p00syIzW5wwFaV4mOvM7L14d7NTvC0fWJOwTlm8rV5KYiISUe2W8uTuxe5+WsJUnMIhfgUcDwwAKoF74+219WOTjrxpTExEIpr6Egt3X7dv3sweBV6Mfy0DChJW7QFUJNtfRpLYEbm9M3EYaSJVe8qzHYJkUFPfO2lmee5eGf86HNh35nIe8LSZTaFmYL8QeDvZ/lSJiUhEdRorMTN7BjgPyDWzMuBO4DwzG0BNV3E1MBbA3UvMbDbwAVAFjEt2ZhLAvOlvWfe2bXs29TGkCeza9QkAywsvSbKmNEcnrXypUdloUffLU04KZ1TMyfqVsarERCQisCfxKImJSFQ6u5OZoCQmIhG6AVxEghbYy46UxEQkymu95rT5UhITkYgqdSdFJGSqxEQkaBoTE5GgqRITkaCpEhORoMVUiYlIyAJ7T4iSmIhEVasSE5GQ6QZwEQmaBvZFJGjVpu6kiAQs6aNUmxklMRGJ0NlJEQmazk6KSNB0dlJEgqbupIgETZdYiEjQYqrERCRkqsREJGhKYiIStMAesa8kJiJRqsREJGi67UhEgqbrxEQkaKF1J1tlOwARaV6qGzAlY2aPm9l6M1uW0NbZzF41s5Xxz04JyyaaWamZrTCzi1KJV0lMRCK8AVMKpgNDDmi7FVjo7oXAwvh3zKwfMBLoH99mqpnlJDuAkpiIRFRb6lMy7v4asPmA5mHAjPj8DOCyhPZZ7r7b3VcBpcDAZMdQEhORiFgDJjMrMrPFCVNRCofo5u6VAPHPY+Lt+cCahPXK4m310sC+iERUN+BhPO5eDBSn6dC11XZJg1ElJiIR6RzYr8M6M8sDiH+uj7eXAQUJ6/UAKpLtTElMRCLSPLBfm3nA6Pj8aGBuQvtIMzvSzHoBhcDbyXam7qSIRKTzOjEzewY4D8g1szLgTuBnwGwzGwN8CowAcPcSM5sNfABUAePcPekNBEpiIhJRZel7QLW7f6OORRfWsf4kYFJDjqEkJiIResa+iAQttNuOlMREJKIhl1g0B0piIhIRVgpTEhORA6g7KSJBiwVWiymJiUiEKjERCZqrEhORkIVWieneyTr8+te/4JNPlrB48Sv72y6//BKWLHmVHTtWceqpX6xz28GDv8Lf//5Hli37M9///nczEW6Llzf5Bgrfeppev5+6vy33+qvp8/qT9Jr3IL3mPUi7r5wW2aZ1Xlf6Ln2OzmMur3WfrTq0p2D6JI5/9VEKpk+i1dHtm/Q3NBfVeMpTc6AkVoeZM59l2LDRkbaSkg8ZOXIsb7yxqM7tWrVqxf33382wYaM55ZRBjBgxlBNPLGzqcFu8rXMWsObbtx/Uvnn671g19HpWDb2eHX9eHFnW7bYitr+2+KBt9skdeyU731zKR4O/w843l9Jl7Ii0x90cZeAG8LRSEqvDX/7yNps3b420rVhRysqVH9e73emnD+Cjj1azevUa9u7dy7PPvsDXvz64CSMVgF3vLCO27fOU128/6Cz2rqlk98pP617nwjPZ9vwCALY9v4CjBp11yHGGoApPeWoOlMTSrHv3Yykrq9z/vby8kvz8Y7MYUcvW6ZuX0uuFh8mbfMP+7qC1PZIuRVew4cGn6922dW5HqjZsAaBqwxZad+nQ5PE2B96Af5qDRicxM/tWPcv2P7K2uDhdD30Mg9XybEr35vHHbmm2PP17PrpwDKuGXkfV+s10m3gtAF3Hf5PNT/wO3/nPLEfYPGXgoYhpdShnJ38MPFHbggMeWesTJjToyRpBKy9fS48eefu/5+fnUVGxLosRtVyxTVv3z2+d/TI9in8EQNsv9eWoIedwzM3fJufodlDt+O49bHnqxcj2VRu30rprp5oqrGsnqjZty2D02dNcKqxU1ZvEzOy9uhYB3dIfTvgWL/47ffr0omfPAioq1jJixKVcc834bIfVIu1LQABHDf4yuz/8BIBPrrp5/zq5119N9c5dByUwgO1/fIsOwwexqfhZOgwfxPaFb2Um8CxrLhVWqpJVYt2Ai4AtB7Qb8GaTRNRMzJjxS8499yxycztRWvoWd999H1u2bGXKlB+Tm9uZOXOe4L33PmDo0P8iL+8Ypk79OcOHX0MsFuPGG+/ghReeJCcnhxkzZrN8+cps/5zDXvf7bqbdwJPJ6XQ0fV5/kg0PPEW7M07myJN6gzt7y9ex9vYHk+4nb9IEtjzzEv9ctpJNjzxL/gMT6Tjiq+yt2EDZ+J9m4JdkXyyw4Q+rb7zGzKYBT7j7G7Use9rdr0rhGN62bc9DCFGyZdeumspleeElWY5EGuOklS+l8GbIg13Vc3jKWezpT55v1DHSqd5KzN3H1LMslQQmIoE5rMbERKTlOdzGxESkhWkutxOlSklMRCLUnRSRoIV2dlJJTEQi1J0UkaBpYF9EgqYxMREJmrqTIhK00J66oiQmIhF6ZZuIBE3dSREJWrq7k2a2GvgciAFV7n6amXUG/hc4DlgNXOnuBz4tJyV6PLWIRDTR247Od/cB7r7vlVO3AgvdvRBYGP/eKEpiIhKRoWfsDwNmxOdnAJc1dkdKYiISEXNPeUp8n0Z8Kqpllw68YmZLEpZ3c/dKgPjnMY2NV2NiIhLRkG7iAe/TqMvZ7l5hZscAr5rZPw4lvgOpEhORiHSPibl7RfxzPfA8MBBYZ2Z5APHP9Y2NV0lMRCLcPeUpGTNrZ2ZH7ZsHvgosA+YBo+OrjQbmNjZedSdFJCLN14l1A563mheytgaedveXzewdYLaZjQE+BUY09gBKYiISkc4bwN39Y+BLtbRvAi5MxzGUxEQkIuZhPYxHSUxEInQDuIgETfdOikjQ9FBEEQlatbqTIhIyVWIiEjSdnRSRoKk7KSJBU3dSRIKmSkxEgqZKTESCFvNYtkNoECUxEYnQbUciEjTddiQiQVMlJiJB09lJEQmazk6KSNB025GIBE1jYiISNI2JiUjQVImJSNB0nZiIBE2VmIgETWcnRSRoGtgXkaCpOykiQdMV+yIStNAqMctAwGH9GxE5fFhjNmrdJj/l/2er9pQ36hjplIkkdlgzsyJ3L852HNI4+vuFr1W2AzgMFGU7ADkk+vsFTklMRIKmJCYiQVMSO3QaTwmb/n6B08C+iARNlZiIBE1JTESCpiTWSGY2xMxWmFmpmd2a7XikYczscTNbb2bLsh2LHBolsUYwsxzgYeBioB/wDTPrl92opIGmA0OyHYQcOiWxxhkIlLr7x+6+B5gFDMtyTNIA7v4asDnbccihUxJrnHxgTcL3snibiGSYkljj1HbTq65VEckCJbHGKQMKEr73ACqyFItIi6Yk1jjvAIVm1svM2gAjgXlZjkmkRVISawR3rwKuA/4ALAdmu3tJdqOShjCzZ4C/An3NrMzMxmQ7Jmkc3XYkIkFTJSYiQVMSE5GgKYmJSNCUxEQkaEpiIhI0JTERCZqSmIgE7f8BpaUKs7AujcIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#prediction\n",
    "train_prediction_svm = modelo_svm.predict(x_train)\n",
    "strain_countBB00=strain_countMB10=strain_countBM01=strain_countMM11=0\n",
    "test_prediction_svm = modelo_svm.predict(x_test)\n",
    "stest_countBB00=stest_countMB10=stest_countBM01=stest_countMM11=0\n",
    "for i in range(train_ourn):\n",
    "    if(train_l[i]=='B' and train_prediction_svm[i]=='B'):\n",
    "        strain_countBB00+=1\n",
    "    elif(train_l[i]=='M' and train_prediction_svm[i]=='B'):\n",
    "        strain_countMB10+=1\n",
    "    elif(train_l[i]=='B' and train_prediction_svm[i]=='M'):\n",
    "        strain_countBM01+=1\n",
    "    else:\n",
    "        strain_countMM11+=1\n",
    "for i in range(test_ourn):\n",
    "    if(test_l[i]=='B' and test_prediction_svm[i]=='B'):\n",
    "        stest_countBB00+=1\n",
    "    elif(test_l[i]=='M' and test_prediction_svm[i]=='B'):\n",
    "        stest_countMB10+=1\n",
    "    elif(test_l[i]=='B' and test_prediction_svm[i]=='M'):\n",
    "        stest_countBM01+=1\n",
    "    else:\n",
    "        stest_countMM11+=1\n",
    "#Results:\n",
    "print(\"TEST DATA\")\n",
    "print(\"True Positive of Test data : \",stest_countMM11)\n",
    "print(\"False Positive of Test data : \",stest_countBM01)\n",
    "print(\"True Negative of Test data : \",stest_countMB10)\n",
    "print(\"False Negative of Test data : \",test_countBB00,\"\\n\")\n",
    "\n",
    "print(\"TRAIN DATA\")\n",
    "print(\"True Positive of Train data : \",strain_countMM11)\n",
    "print(\"False Positive of Train data : \",strain_countBM01)\n",
    "print(\"True Negative of Train data : \",strain_countMB10)\n",
    "print(\"False Negative of Train data : \",strain_countBB00,\"\\n\")\n",
    "\n",
    "stest_acc=(stest_countMM11+stest_countBB00)/(stest_countMM11+stest_countMB10+stest_countBB00+stest_countBM01)\n",
    "stest_sens=stest_recall=stest_countMM11/(stest_countMM11+stest_countMB10)\n",
    "stest_spec=stest_countBB00/(stest_countMB10+stest_countBB00)\n",
    "stest_prec=stest_countMM11/(stest_countMM11+stest_countMB10)\n",
    "stest_f1=(2*stest_prec*stest_recall)/(stest_prec+stest_recall)\n",
    "print(\"Test data accuracy : \",round(stest_acc,4))\n",
    "print(\"Test data sensitivity : \",round(stest_sens,4))\n",
    "print(\"Test data specificity : \",round(stest_spec,4))\n",
    "print(\"Test data f1-score : \",round(stest_f1,4))\n",
    "\n",
    "strain_acc=(strain_countMM11+strain_countBB00)/(strain_countMM11+strain_countMB10+strain_countBB00+strain_countBM01)\n",
    "strain_sens=strain_recall=strain_countMM11/(strain_countMM11+strain_countMB10)\n",
    "strain_spec=strain_countBB00/(strain_countMB10+strain_countBB00)\n",
    "strain_prec=strain_countMM11/(strain_countMM11+strain_countMB10)\n",
    "strain_f1=(2*strain_prec*strain_recall)/(strain_prec+strain_recall)\n",
    "print(\"Train data accuracy : \",round(strain_acc,4))\n",
    "print(\"Train data sensitivity : \",round(strain_sens,4))\n",
    "print(\"Train data specificity : \",round(strain_spec,4))\n",
    "print(\"Train data f1-score : \",round(strain_f1,4))\n",
    "\n",
    "#Clasification report\n",
    "test_results_svm=metrics.classification_report(y_true=y_test, y_pred=test_prediction_svm)\n",
    "print(test_results_svm,\"\\n\")\n",
    "\n",
    "train_results_svm=metrics.classification_report(y_true=y_train,y_pred=train_prediction_svm)\n",
    "print(train_results_svm)\n",
    "\n",
    "#Confusion matrix\n",
    "test_cm_svm=metrics.confusion_matrix(y_true=y_test, y_pred=test_prediction_svm)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(test_cm_svm, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n",
    "\n",
    "train_cm_svm=metrics.confusion_matrix(y_true=y_train, y_pred=train_prediction_svm)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(train_cm_svm, annot=True, linewidths=.5, fmt= '.1f',ax=ax),\"\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad87a863",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00078: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Deep Neural Network with Keras\n",
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Using \"Binary_crossentropy\"\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be4bd000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Class prediction\n",
    "#prediction_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "#prediction_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "prediction_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "# Clasification report\n",
    "results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=prediction_DNN)\n",
    "print (results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f9e08fa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss']);\n",
    "plt.plot(history.history['val_loss']);\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1f577c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.62x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm_DNN=metrics.confusion_matrix(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=prediction_DNN)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(cm_DNN, annot=True, linewidths=.5, fmt= '.1f',ax=ax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67943d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00086: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Artificial Neural Network with Keras\n",
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "# Adding the second hidden layer\n",
    "model.add(Dense(units=160, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "# Adding the output layer\n",
    "model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "# Using \"Binary_crossentropy\"\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Adjusted the model using the previous cost optimizer and function\n",
    "earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b8c99a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Class prediction\n",
    "#prediction_ANN = model.predict_classess(x_test, batch_size=32)\n",
    "#prediction_ANN = np.argmax(model.predict(x_test), axis=-1)\n",
    "prediction_ANN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "# Clasification report\n",
    "results_ANN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=prediction_ANN)\n",
    "print (results_ANN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a40ae99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarize history for loss\n",
    "plt.plot(history.history['loss']);\n",
    "plt.plot(history.history['val_loss']);\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','validation'], loc='upper right');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdf21e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.62x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "cm_ANN=metrics.confusion_matrix(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=prediction_ANN)\n",
    "f,ax = plt.subplots(figsize=(5, 4))\n",
    "print(sns.heatmap(cm_ANN, annot=True, linewidths=.5, fmt= '.1f',ax=ax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74fb8229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00040: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vara\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Vara\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Vara\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00099: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "Epoch 00085: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00082: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00071: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00064: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "Epoch 00068: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "Epoch 00069: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00062: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00057: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "l=[]\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+50, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+60, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+70, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+80, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+90, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+100, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "37e751a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for item in l:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ffe88ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00206: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00072: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00074: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00109: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00054: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00071: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00069: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00073: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00083: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00081: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "30d086db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "278efb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00100: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00067: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00066: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00042: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00043: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00040: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00043: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00033: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00035: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00050: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95c878a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1dc85b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00152: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00059: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00046: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00057: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00050: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00050: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00038: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "Epoch 00034: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00029: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "Epoch 00050: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    \n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0901acb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "20a62111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00070: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "Epoch 00075: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00044: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "Epoch 00082: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00061: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "Epoch 00040: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00052: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "Epoch 00038: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "Epoch 00056: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00049: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3966d1aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "41               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "47               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "50               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i,item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5f3655ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00086: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00060: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00076: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00046: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        67\n",
      "           1       1.00      0.66      0.79        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.90      0.83      0.84       114\n",
      "weighted avg       0.89      0.86      0.85       114\n",
      "\n",
      "Epoch 00070: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00038: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        67\n",
      "           1       0.73      0.94      0.82        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.84      0.85      0.83       114\n",
      "weighted avg       0.86      0.83      0.83       114\n",
      "\n",
      "Epoch 00067: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00046: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        67\n",
      "           1       0.77      0.91      0.83        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.85      0.86      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "Epoch 00038: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        67\n",
      "           1       0.97      0.74      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "Epoch 00031: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        67\n",
      "           1       1.00      0.64      0.78        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.90      0.82      0.83       114\n",
      "weighted avg       0.88      0.85      0.84       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+50, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "aa7f7afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "41               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "47               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "50               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        67\n",
      "           1       1.00      0.66      0.79        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.90      0.83      0.84       114\n",
      "weighted avg       0.89      0.86      0.85       114\n",
      "\n",
      "55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        67\n",
      "           1       0.73      0.94      0.82        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.84      0.85      0.83       114\n",
      "weighted avg       0.86      0.83      0.83       114\n",
      "\n",
      "57               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        67\n",
      "           1       0.77      0.91      0.83        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.85      0.86      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        67\n",
      "           1       0.97      0.74      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "60               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        67\n",
      "           1       1.00      0.64      0.78        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.90      0.82      0.83       114\n",
      "weighted avg       0.88      0.85      0.84       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "40affe0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00085: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "Epoch 00055: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00052: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "Epoch 00054: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        67\n",
      "           1       0.81      0.89      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.87      0.87       114\n",
      "weighted avg       0.87      0.87      0.87       114\n",
      "\n",
      "Epoch 00079: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00046: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "Epoch 00068: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "Epoch 00070: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00036: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        67\n",
      "           1       1.00      0.60      0.75        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.89      0.80      0.81       114\n",
      "weighted avg       0.87      0.83      0.82       114\n",
      "\n",
      "Epoch 00060: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+50, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+60, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bb674cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "41               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "47               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "50               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        67\n",
      "           1       1.00      0.66      0.79        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.90      0.83      0.84       114\n",
      "weighted avg       0.89      0.86      0.85       114\n",
      "\n",
      "55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        67\n",
      "           1       0.73      0.94      0.82        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.84      0.85      0.83       114\n",
      "weighted avg       0.86      0.83      0.83       114\n",
      "\n",
      "57               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        67\n",
      "           1       0.77      0.91      0.83        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.85      0.86      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        67\n",
      "           1       0.97      0.74      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "60               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        67\n",
      "           1       1.00      0.64      0.78        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.90      0.82      0.83       114\n",
      "weighted avg       0.88      0.85      0.84       114\n",
      "\n",
      "61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        67\n",
      "           1       0.81      0.89      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.87      0.87       114\n",
      "weighted avg       0.87      0.87      0.87       114\n",
      "\n",
      "65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "69               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        67\n",
      "           1       1.00      0.60      0.75        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.89      0.80      0.81       114\n",
      "weighted avg       0.87      0.83      0.82       114\n",
      "\n",
      "70               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7537a298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00095: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89        67\n",
      "           1       0.82      0.89      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "Epoch 00063: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92        67\n",
      "           1       0.88      0.89      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "Epoch 00069: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        67\n",
      "           1       0.91      0.89      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "Epoch 00094: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        67\n",
      "           1       0.86      0.91      0.89        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "Epoch 00059: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00048: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        67\n",
      "           1       0.97      0.77      0.86        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n",
      "Epoch 00045: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        67\n",
      "           1       0.80      0.87      0.84        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.85      0.86      0.86       114\n",
      "weighted avg       0.86      0.86      0.86       114\n",
      "\n",
      "Epoch 00043: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "Epoch 00052: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00031: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+50, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+60, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+70, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ec93e4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "41               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "47               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "50               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        67\n",
      "           1       1.00      0.66      0.79        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.90      0.83      0.84       114\n",
      "weighted avg       0.89      0.86      0.85       114\n",
      "\n",
      "55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        67\n",
      "           1       0.73      0.94      0.82        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.84      0.85      0.83       114\n",
      "weighted avg       0.86      0.83      0.83       114\n",
      "\n",
      "57               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        67\n",
      "           1       0.77      0.91      0.83        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.85      0.86      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        67\n",
      "           1       0.97      0.74      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "60               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        67\n",
      "           1       1.00      0.64      0.78        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.90      0.82      0.83       114\n",
      "weighted avg       0.88      0.85      0.84       114\n",
      "\n",
      "61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        67\n",
      "           1       0.81      0.89      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.87      0.87       114\n",
      "weighted avg       0.87      0.87      0.87       114\n",
      "\n",
      "65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "69               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        67\n",
      "           1       1.00      0.60      0.75        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.89      0.80      0.81       114\n",
      "weighted avg       0.87      0.83      0.82       114\n",
      "\n",
      "70               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89        67\n",
      "           1       0.82      0.89      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92        67\n",
      "           1       0.88      0.89      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        67\n",
      "           1       0.91      0.89      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        67\n",
      "           1       0.86      0.91      0.89        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        67\n",
      "           1       0.97      0.77      0.86        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n",
      "77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        67\n",
      "           1       0.80      0.87      0.84        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.85      0.86      0.86       114\n",
      "weighted avg       0.86      0.86      0.86       114\n",
      "\n",
      "78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "80               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "20389dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00110: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00094: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00085: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        67\n",
      "           1       0.83      0.94      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "Epoch 00063: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "Epoch 00051: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "Epoch 00042: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "Epoch 00049: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        67\n",
      "           1       1.00      0.77      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.90       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "Epoch 00077: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00075: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "Epoch 00054: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+50, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+60, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+70, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+80, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7eb0c13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "41               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "47               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "50               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        67\n",
      "           1       1.00      0.66      0.79        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.90      0.83      0.84       114\n",
      "weighted avg       0.89      0.86      0.85       114\n",
      "\n",
      "55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        67\n",
      "           1       0.73      0.94      0.82        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.84      0.85      0.83       114\n",
      "weighted avg       0.86      0.83      0.83       114\n",
      "\n",
      "57               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        67\n",
      "           1       0.77      0.91      0.83        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.85      0.86      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        67\n",
      "           1       0.97      0.74      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "60               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        67\n",
      "           1       1.00      0.64      0.78        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.90      0.82      0.83       114\n",
      "weighted avg       0.88      0.85      0.84       114\n",
      "\n",
      "61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        67\n",
      "           1       0.81      0.89      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.87      0.87       114\n",
      "weighted avg       0.87      0.87      0.87       114\n",
      "\n",
      "65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "69               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        67\n",
      "           1       1.00      0.60      0.75        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.89      0.80      0.81       114\n",
      "weighted avg       0.87      0.83      0.82       114\n",
      "\n",
      "70               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89        67\n",
      "           1       0.82      0.89      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92        67\n",
      "           1       0.88      0.89      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        67\n",
      "           1       0.91      0.89      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        67\n",
      "           1       0.86      0.91      0.89        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        67\n",
      "           1       0.97      0.77      0.86        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n",
      "77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        67\n",
      "           1       0.80      0.87      0.84        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.85      0.86      0.86       114\n",
      "weighted avg       0.86      0.86      0.86       114\n",
      "\n",
      "78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "80               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "81               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "82               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "83               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        67\n",
      "           1       0.83      0.94      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "84               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "85               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "86               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "87               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        67\n",
      "           1       1.00      0.77      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.90       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "88               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "89               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "90               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "64b99437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 00097: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        67\n",
      "           1       0.84      0.91      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "Epoch 00086: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89        67\n",
      "           1       0.81      0.91      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.88       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "Epoch 00080: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "Epoch 00054: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        67\n",
      "           1       0.86      0.89      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.89      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "Epoch 00047: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "Epoch 00064: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "Epoch 00046: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "Epoch 00038: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        67\n",
      "           1       1.00      0.72      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "Epoch 00043: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        67\n",
      "           1       1.00      0.77      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.90       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "Epoch 00038: early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        67\n",
      "           1       1.00      0.47      0.64        47\n",
      "\n",
      "    accuracy                           0.78       114\n",
      "   macro avg       0.86      0.73      0.74       114\n",
      "weighted avg       0.84      0.78      0.76       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras import callbacks\n",
    "# Create the model: many layers\n",
    "for i in range(10,110,10):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu', input_dim=30))\n",
    "\n",
    "    # Adding the second hidden layer\n",
    "    model.add(Dense(units=i, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+20, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+30, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+40, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+50, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+60, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+70, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(units=i+80, kernel_initializer='uniform', activation='relu'))\n",
    "\n",
    "\n",
    "    # Adding the output layer\n",
    "    model.add(Dense(units=1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    # Using \"Binary_crossentropy\"\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    # Adjusted the model using the previous cost optimizer and function\n",
    "    earlystop=callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=5, mode='auto',verbose=1)\n",
    "    history=model.fit(x_train, pd.get_dummies(y_train,drop_first=True)['M'].values, validation_split=0.2, epochs=500, batch_size=5000, verbose=0, callbacks=[earlystop])\n",
    "    # Class prediction\n",
    "    #predicion_DNN = model.predict_classess(x_test, batch_size=32)\n",
    "    #predicion_DNN = np.argmax(model.predict(x_test), axis=-1)\n",
    "    predicion_DNN = (model.predict(x_test) > 0.5).astype(\"int32\")\n",
    "    # Clasification report\n",
    "    results_DNN =metrics.classification_report(y_true=pd.get_dummies(y_test,drop_first=True), y_pred=predicion_DNN)\n",
    "    print (results_DNN)\n",
    "    l.append(results_DNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a1fc96a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      1.00      0.74        67\n",
      "           1       0.00      0.00      0.00        47\n",
      "\n",
      "    accuracy                           0.59       114\n",
      "   macro avg       0.29      0.50      0.37       114\n",
      "weighted avg       0.35      0.59      0.44       114\n",
      "\n",
      "2               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.90        67\n",
      "           1       0.83      0.91      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "3               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "4               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "5               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.93      0.93        67\n",
      "           1       0.90      0.91      0.91        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "6               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89        67\n",
      "           1       0.80      0.94      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.89      0.88       114\n",
      "weighted avg       0.89      0.88      0.88       114\n",
      "\n",
      "7               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90        67\n",
      "           1       0.81      0.94      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "8               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.96      0.94        67\n",
      "           1       0.93      0.89      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "9               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "10               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "11               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "12               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "13               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "14               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "15               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "16               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "17               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "18               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "19               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.95        67\n",
      "           1       0.98      0.87      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.95      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "20               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "21               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "22               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "23               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "24               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "25               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "26               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "27               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "28               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "29               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "30               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94        67\n",
      "           1       0.95      0.87      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.93      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "31               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "32               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "33               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "34               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "35               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "36               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "37               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92        67\n",
      "           1       0.91      0.85      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "38               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "39               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "40               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "41               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "42               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "43               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "44               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "45               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "46               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "47               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "48               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "49               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "50               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "51               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "52               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "53               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "54               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      1.00      0.89        67\n",
      "           1       1.00      0.66      0.79        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.90      0.83      0.84       114\n",
      "weighted avg       0.89      0.86      0.85       114\n",
      "\n",
      "55               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "56               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.76      0.84        67\n",
      "           1       0.73      0.94      0.82        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.84      0.85      0.83       114\n",
      "weighted avg       0.86      0.83      0.83       114\n",
      "\n",
      "57               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "58               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.81      0.86        67\n",
      "           1       0.77      0.91      0.83        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.85      0.86      0.85       114\n",
      "weighted avg       0.86      0.85      0.85       114\n",
      "\n",
      "59               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.99      0.91        67\n",
      "           1       0.97      0.74      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.91      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "60               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      1.00      0.89        67\n",
      "           1       1.00      0.64      0.78        47\n",
      "\n",
      "    accuracy                           0.85       114\n",
      "   macro avg       0.90      0.82      0.83       114\n",
      "weighted avg       0.88      0.85      0.84       114\n",
      "\n",
      "61               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "62               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.97      0.94        67\n",
      "           1       0.95      0.85      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "63               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "64               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.85      0.88        67\n",
      "           1       0.81      0.89      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.87      0.87       114\n",
      "weighted avg       0.87      0.87      0.87       114\n",
      "\n",
      "65               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "66               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        67\n",
      "           1       1.00      0.74      0.85        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.87      0.89       114\n",
      "weighted avg       0.91      0.89      0.89       114\n",
      "\n",
      "67               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "68               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "69               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      1.00      0.88        67\n",
      "           1       1.00      0.60      0.75        47\n",
      "\n",
      "    accuracy                           0.83       114\n",
      "   macro avg       0.89      0.80      0.81       114\n",
      "weighted avg       0.87      0.83      0.82       114\n",
      "\n",
      "70               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "71               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.87      0.89        67\n",
      "           1       0.82      0.89      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.87       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "72               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.91      0.92        67\n",
      "           1       0.88      0.89      0.88        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.90      0.90       114\n",
      "weighted avg       0.90      0.90      0.90       114\n",
      "\n",
      "73               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.94      0.93        67\n",
      "           1       0.91      0.89      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.92      0.92      0.92       114\n",
      "weighted avg       0.92      0.92      0.92       114\n",
      "\n",
      "74               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92        67\n",
      "           1       0.86      0.91      0.89        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.90      0.91      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "75               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "76               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.99      0.92        67\n",
      "           1       0.97      0.77      0.86        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.88      0.89       114\n",
      "weighted avg       0.90      0.89      0.89       114\n",
      "\n",
      "77               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.85      0.88        67\n",
      "           1       0.80      0.87      0.84        47\n",
      "\n",
      "    accuracy                           0.86       114\n",
      "   macro avg       0.85      0.86      0.86       114\n",
      "weighted avg       0.86      0.86      0.86       114\n",
      "\n",
      "78               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "79               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "80               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "81               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "82               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "83               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91        67\n",
      "           1       0.83      0.94      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "84               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.84      0.88        67\n",
      "           1       0.80      0.91      0.85        47\n",
      "\n",
      "    accuracy                           0.87       114\n",
      "   macro avg       0.86      0.88      0.87       114\n",
      "weighted avg       0.88      0.87      0.87       114\n",
      "\n",
      "85               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94        67\n",
      "           1       0.97      0.83      0.90        47\n",
      "\n",
      "    accuracy                           0.92       114\n",
      "   macro avg       0.93      0.91      0.92       114\n",
      "weighted avg       0.93      0.92      0.92       114\n",
      "\n",
      "86               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93        67\n",
      "           1       0.93      0.85      0.89        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.92      0.90      0.91       114\n",
      "weighted avg       0.91      0.91      0.91       114\n",
      "\n",
      "87               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        67\n",
      "           1       1.00      0.77      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.90       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "88               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "89               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94        67\n",
      "           1       0.98      0.85      0.91        47\n",
      "\n",
      "    accuracy                           0.93       114\n",
      "   macro avg       0.94      0.92      0.93       114\n",
      "weighted avg       0.93      0.93      0.93       114\n",
      "\n",
      "90               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95        67\n",
      "           1       0.95      0.89      0.92        47\n",
      "\n",
      "    accuracy                           0.94       114\n",
      "   macro avg       0.94      0.93      0.94       114\n",
      "weighted avg       0.94      0.94      0.94       114\n",
      "\n",
      "91               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91        67\n",
      "           1       0.84      0.91      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.90      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "92               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.85      0.89        67\n",
      "           1       0.81      0.91      0.86        47\n",
      "\n",
      "    accuracy                           0.88       114\n",
      "   macro avg       0.87      0.88      0.88       114\n",
      "weighted avg       0.88      0.88      0.88       114\n",
      "\n",
      "93               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90        67\n",
      "           1       0.84      0.89      0.87        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.88      0.89      0.88       114\n",
      "weighted avg       0.89      0.89      0.89       114\n",
      "\n",
      "94               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91        67\n",
      "           1       0.86      0.89      0.88        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.89      0.89      0.89       114\n",
      "weighted avg       0.90      0.89      0.90       114\n",
      "\n",
      "95               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.99      0.93        67\n",
      "           1       0.97      0.81      0.88        47\n",
      "\n",
      "    accuracy                           0.91       114\n",
      "   macro avg       0.93      0.90      0.91       114\n",
      "weighted avg       0.92      0.91      0.91       114\n",
      "\n",
      "96               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96        67\n",
      "           1       0.98      0.89      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.94       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n",
      "97               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.99      0.92        67\n",
      "           1       0.97      0.79      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.92      0.89      0.90       114\n",
      "weighted avg       0.91      0.90      0.90       114\n",
      "\n",
      "98               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91        67\n",
      "           1       1.00      0.72      0.84        47\n",
      "\n",
      "    accuracy                           0.89       114\n",
      "   macro avg       0.92      0.86      0.88       114\n",
      "weighted avg       0.90      0.89      0.88       114\n",
      "\n",
      "99               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      1.00      0.92        67\n",
      "           1       1.00      0.77      0.87        47\n",
      "\n",
      "    accuracy                           0.90       114\n",
      "   macro avg       0.93      0.88      0.90       114\n",
      "weighted avg       0.92      0.90      0.90       114\n",
      "\n",
      "100               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      1.00      0.84        67\n",
      "           1       1.00      0.47      0.64        47\n",
      "\n",
      "    accuracy                           0.78       114\n",
      "   macro avg       0.86      0.73      0.74       114\n",
      "weighted avg       0.84      0.78      0.76       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for item in l:\n",
    "    print(i, item)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ddd654e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn100(cr):\n",
    "    eachdnn=[]\n",
    "    lines = cr.split('\\n')\n",
    "    eachdnn_aux=lines[6].split()\n",
    "    for i in range(2,5):\n",
    "        eachdnn.append(float(eachdnn_aux[i]))\n",
    "    return eachdnn     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "183b487b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [0.29, 0.5, 0.37]\n",
      "2 [0.88, 0.89, 0.88]\n",
      "3 [0.95, 0.94, 0.95]\n",
      "4 [0.95, 0.94, 0.94]\n",
      "5 [0.92, 0.92, 0.92]\n",
      "6 [0.87, 0.89, 0.88]\n",
      "7 [0.88, 0.89, 0.88]\n",
      "8 [0.93, 0.92, 0.93]\n",
      "9 [0.94, 0.93, 0.94]\n",
      "10 [0.95, 0.94, 0.95]\n",
      "11 [0.95, 0.93, 0.94]\n",
      "12 [0.94, 0.92, 0.93]\n",
      "13 [0.95, 0.94, 0.94]\n",
      "14 [0.95, 0.93, 0.94]\n",
      "15 [0.95, 0.94, 0.94]\n",
      "16 [0.95, 0.93, 0.94]\n",
      "17 [0.95, 0.94, 0.94]\n",
      "18 [0.95, 0.94, 0.94]\n",
      "19 [0.95, 0.93, 0.94]\n",
      "20 [0.95, 0.94, 0.94]\n",
      "21 [0.94, 0.92, 0.93]\n",
      "22 [0.94, 0.92, 0.93]\n",
      "23 [0.94, 0.92, 0.93]\n",
      "24 [0.94, 0.92, 0.93]\n",
      "25 [0.94, 0.92, 0.93]\n",
      "26 [0.94, 0.92, 0.93]\n",
      "27 [0.94, 0.93, 0.94]\n",
      "28 [0.94, 0.92, 0.93]\n",
      "29 [0.94, 0.92, 0.93]\n",
      "30 [0.93, 0.92, 0.93]\n",
      "31 [0.94, 0.92, 0.93]\n",
      "32 [0.94, 0.93, 0.94]\n",
      "33 [0.93, 0.91, 0.92]\n",
      "34 [0.94, 0.92, 0.93]\n",
      "35 [0.93, 0.91, 0.92]\n",
      "36 [0.93, 0.91, 0.92]\n",
      "37 [0.9, 0.9, 0.9]\n",
      "38 [0.93, 0.91, 0.92]\n",
      "39 [0.92, 0.9, 0.91]\n",
      "40 [0.93, 0.91, 0.92]\n",
      "41 [0.94, 0.93, 0.94]\n",
      "42 [0.93, 0.91, 0.92]\n",
      "43 [0.92, 0.9, 0.91]\n",
      "44 [0.93, 0.91, 0.92]\n",
      "45 [0.93, 0.9, 0.91]\n",
      "46 [0.93, 0.91, 0.92]\n",
      "47 [0.93, 0.9, 0.91]\n",
      "48 [0.92, 0.87, 0.89]\n",
      "49 [0.93, 0.91, 0.92]\n",
      "50 [0.93, 0.91, 0.92]\n",
      "51 [0.94, 0.92, 0.93]\n",
      "52 [0.95, 0.94, 0.94]\n",
      "53 [0.94, 0.92, 0.93]\n",
      "54 [0.9, 0.83, 0.84]\n",
      "55 [0.93, 0.91, 0.92]\n",
      "56 [0.84, 0.85, 0.83]\n",
      "57 [0.93, 0.91, 0.92]\n",
      "58 [0.85, 0.86, 0.85]\n",
      "59 [0.91, 0.86, 0.88]\n",
      "60 [0.9, 0.82, 0.83]\n",
      "61 [0.88, 0.89, 0.88]\n",
      "62 [0.93, 0.91, 0.92]\n",
      "63 [0.93, 0.9, 0.91]\n",
      "64 [0.86, 0.87, 0.87]\n",
      "65 [0.94, 0.92, 0.93]\n",
      "66 [0.92, 0.87, 0.89]\n",
      "67 [0.92, 0.89, 0.9]\n",
      "68 [0.94, 0.92, 0.93]\n",
      "69 [0.89, 0.8, 0.81]\n",
      "70 [0.93, 0.91, 0.92]\n",
      "71 [0.87, 0.88, 0.87]\n",
      "72 [0.9, 0.9, 0.9]\n",
      "73 [0.92, 0.92, 0.92]\n",
      "74 [0.9, 0.91, 0.9]\n",
      "75 [0.93, 0.91, 0.92]\n",
      "76 [0.92, 0.88, 0.89]\n",
      "77 [0.85, 0.86, 0.86]\n",
      "78 [0.86, 0.88, 0.87]\n",
      "79 [0.94, 0.92, 0.93]\n",
      "80 [0.93, 0.9, 0.91]\n",
      "81 [0.95, 0.94, 0.94]\n",
      "82 [0.95, 0.94, 0.95]\n",
      "83 [0.89, 0.9, 0.89]\n",
      "84 [0.86, 0.88, 0.87]\n",
      "85 [0.93, 0.91, 0.92]\n",
      "86 [0.92, 0.9, 0.91]\n",
      "87 [0.93, 0.88, 0.9]\n",
      "88 [0.95, 0.94, 0.94]\n",
      "89 [0.94, 0.92, 0.93]\n",
      "90 [0.94, 0.93, 0.94]\n",
      "91 [0.89, 0.9, 0.89]\n",
      "92 [0.87, 0.88, 0.88]\n",
      "93 [0.88, 0.89, 0.88]\n",
      "94 [0.89, 0.89, 0.89]\n",
      "95 [0.93, 0.9, 0.91]\n",
      "96 [0.95, 0.94, 0.94]\n",
      "97 [0.92, 0.89, 0.9]\n",
      "98 [0.92, 0.86, 0.88]\n",
      "99 [0.93, 0.88, 0.9]\n",
      "100 [0.86, 0.73, 0.74]\n",
      "1:  0.3866666666666667\n",
      "2:  0.8833333333333333\n",
      "3:  0.9466666666666667\n",
      "4:  0.9433333333333334\n",
      "5:  0.92\n",
      "6:  0.88\n",
      "7:  0.8833333333333333\n",
      "8:  0.9266666666666667\n",
      "9:  0.9366666666666666\n",
      "10:  0.9466666666666667\n",
      "11:  0.94\n",
      "12:  0.93\n",
      "13:  0.9433333333333334\n",
      "14:  0.94\n",
      "15:  0.9433333333333334\n",
      "16:  0.94\n",
      "17:  0.9433333333333334\n",
      "18:  0.9433333333333334\n",
      "19:  0.94\n",
      "20:  0.9433333333333334\n",
      "21:  0.93\n",
      "22:  0.93\n",
      "23:  0.93\n",
      "24:  0.93\n",
      "25:  0.93\n",
      "26:  0.93\n",
      "27:  0.9366666666666666\n",
      "28:  0.93\n",
      "29:  0.93\n",
      "30:  0.9266666666666667\n",
      "31:  0.93\n",
      "32:  0.9366666666666666\n",
      "33:  0.92\n",
      "34:  0.93\n",
      "35:  0.92\n",
      "36:  0.92\n",
      "37:  0.9\n",
      "38:  0.92\n",
      "39:  0.91\n",
      "40:  0.92\n",
      "41:  0.9366666666666666\n",
      "42:  0.92\n",
      "43:  0.91\n",
      "44:  0.92\n",
      "45:  0.9133333333333334\n",
      "46:  0.92\n",
      "47:  0.9133333333333334\n",
      "48:  0.8933333333333334\n",
      "49:  0.92\n",
      "50:  0.92\n",
      "51:  0.93\n",
      "52:  0.9433333333333334\n",
      "53:  0.93\n",
      "54:  0.8566666666666666\n",
      "55:  0.92\n",
      "56:  0.84\n",
      "57:  0.92\n",
      "58:  0.8533333333333334\n",
      "59:  0.8833333333333333\n",
      "60:  0.85\n",
      "61:  0.8833333333333333\n",
      "62:  0.92\n",
      "63:  0.9133333333333334\n",
      "64:  0.8666666666666667\n",
      "65:  0.93\n",
      "66:  0.8933333333333334\n",
      "67:  0.9033333333333333\n",
      "68:  0.93\n",
      "69:  0.8333333333333334\n",
      "70:  0.92\n",
      "71:  0.8733333333333334\n",
      "72:  0.9\n",
      "73:  0.92\n",
      "74:  0.9033333333333333\n",
      "75:  0.92\n",
      "76:  0.8966666666666666\n",
      "77:  0.8566666666666666\n",
      "78:  0.87\n",
      "79:  0.93\n",
      "80:  0.9133333333333334\n",
      "81:  0.9433333333333334\n",
      "82:  0.9466666666666667\n",
      "83:  0.8933333333333334\n",
      "84:  0.87\n",
      "85:  0.92\n",
      "86:  0.91\n",
      "87:  0.9033333333333333\n",
      "88:  0.9433333333333334\n",
      "89:  0.93\n",
      "90:  0.9366666666666666\n",
      "91:  0.8933333333333334\n",
      "92:  0.8766666666666666\n",
      "93:  0.8833333333333333\n",
      "94:  0.89\n",
      "95:  0.9133333333333334\n",
      "96:  0.9433333333333334\n",
      "97:  0.9033333333333333\n",
      "98:  0.8866666666666667\n",
      "99:  0.9033333333333333\n",
      "100:  0.7766666666666667\n",
      "INDEX OF OPTIMIZED DNN:2\n"
     ]
    }
   ],
   "source": [
    "total100dnn=[]\n",
    "avglist=[]\n",
    "for i in range(len(l)):\n",
    "    total100dnn.append(dnn100(l[i]))\n",
    "for i in range(len(total100dnn)):\n",
    "    print(i+1,total100dnn[i])\n",
    "for i in range(len(total100dnn)):\n",
    "    avglist.append(sum(total100dnn[i])/3)\n",
    "for i in range(len(avglist)):\n",
    "    print(str(i+1)+\":  \"+str(avglist[i]))\n",
    "print(\"INDEX OF OPTIMIZED DNN:\"+str(avglist.index(max(avglist))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ead51ba0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96        67\n",
      "           1       0.96      0.91      0.93        47\n",
      "\n",
      "    accuracy                           0.95       114\n",
      "   macro avg       0.95      0.94      0.95       114\n",
      "weighted avg       0.95      0.95      0.95       114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(l[avglist.index(max(avglist))])\n",
    "results_OptimizedDNN=l[avglist.index(max(avglist))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5a394296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resultados_classification_report(cr):\n",
    "    total=[]\n",
    "    lines = cr.split('\\n')\n",
    "    total_aux=lines[6].split()\n",
    "    for i in range(2,5):\n",
    "        total.append(float(total_aux[i]))\n",
    "    return total        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "826f8f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.95, 0.96, 0.96], [0.95, 0.96, 0.95], [0.96, 0.96, 0.96], [0.95, 0.96, 0.96], [0.86, 0.73, 0.74], [0.95, 0.94, 0.94], [0.95, 0.94, 0.95]]\n",
      "PRECISION OF ALL MODELS : [0.95, 0.95, 0.96, 0.95, 0.86, 0.95, 0.95]\n",
      "RECALL OF ALL MODELS : [0.96, 0.96, 0.96, 0.96, 0.73, 0.94, 0.94]\n",
      "F1-SCORE OF ALL MODELS : [0.96, 0.95, 0.96, 0.96, 0.74, 0.94, 0.95]\n"
     ]
    }
   ],
   "source": [
    "names=['LogisticRegression','GradientBoost','Random Forest','SVM','Deep Neural Network','ANN','Optimized DNN']\n",
    "modelResults=[]\n",
    "modelResults.append(test_results_rl)\n",
    "modelResults.append(test_results_gd)\n",
    "modelResults.append(test_results_rf)\n",
    "modelResults.append(test_results_svm)\n",
    "modelResults.append(results_DNN)\n",
    "modelResults.append(results_ANN)\n",
    "modelResults.append(results_OptimizedDNN)\n",
    "\n",
    "totalResults=[]\n",
    "totalPrecision=[]\n",
    "totalRecall=[]\n",
    "totalF=[]\n",
    "for i in range(len(modelResults)):\n",
    "    totalResults.append(resultados_classification_report(modelResults[i]))\n",
    "print(totalResults)\n",
    "   \n",
    "for i in range(len(totalResults)):\n",
    "     totalPrecision.append(totalResults[i][0])\n",
    "     totalRecall.append(totalResults[i][1])\n",
    "     totalF.append(totalResults[i][2])\n",
    "print(\"PRECISION OF ALL MODELS : \"+str(totalPrecision))\n",
    "print(\"RECALL OF ALL MODELS : \"+str(totalRecall))\n",
    "print(\"F1-SCORE OF ALL MODELS : \"+str(totalF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8239bf30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x1f4a048ea00>,\n",
       "  <matplotlib.axis.XTick at 0x1f4a048e250>,\n",
       "  <matplotlib.axis.XTick at 0x1f4a0441a00>,\n",
       "  <matplotlib.axis.XTick at 0x1f4a29b7940>,\n",
       "  <matplotlib.axis.XTick at 0x1f4a29b7b20>,\n",
       "  <matplotlib.axis.XTick at 0x1f4a29b7100>,\n",
       "  <matplotlib.axis.XTick at 0x1f49e083fd0>],\n",
       " [Text(0.3, 0, 'LogisticRegression'),\n",
       "  Text(1.3, 0, 'GradientBoost'),\n",
       "  Text(2.3, 0, 'Random Forest'),\n",
       "  Text(3.3, 0, 'SVM'),\n",
       "  Text(4.3, 0, 'Deep Neural Network'),\n",
       "  Text(5.3, 0, 'ANN'),\n",
       "  Text(6.3, 0, 'Optimized DNN')])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA6IAAAGrCAYAAADaaCpmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAy1klEQVR4nO3deZglZX0+7ufjoLLvxCiIjAlqUGCUcSGKgEREo0EjGJawGA3BSDQajfjTL+IaDSYawECIIuISjAoEFTdEcEGQUUcWBUVFmWgUAVE2YeD9/VHVw5mme6aBnuqe5r6vq6+u/byn6lTVeep9q0611gIAAABDud9MFwAAAID7FkEUAACAQQmiAAAADEoQBQAAYFCCKAAAAIMSRAEAABiUIArAfUpVnVNVL57pcqxMVb2kqn5RVTdU1SYzXR4AmE6CKAAzpqqurKqb+7D1f1V1UlWtO+DrH1xVX52mZe1aVRdX1a+r6pqqOq2qNh8Z/8CqOrGqftO/11euYFn3T/KvSXZvra3bWrvmXpRrq6pqVbXGPV0GAEw3QRSAmfac1tq6SRYkeWyS185sce6x7yZ5RmttwyQPSfKDJMeNjD8yydZJHpZk1yT/WFV7TLKsByVZM8mlq6qwU1Ud3xcAmFZOLADMCq21/0vyuXSBNElSVU+qqvP6WsbvVNUuI+MOrqofVdVvq+rHVbV/P/zIqvrQyHQT1ghW1R8lOT7Jjn2N7K/74c+qqu/2y/3fqnrVFMv/i9baz0YG3Z7kD0f6D0zy5tbada217yX5zyQHj19OVT0iyeV976+r6ux++KOq6gtVdW1VXV5VLxiZ50+r6tt9betVVXXkyCK/PLKsG6pqx5Wto7758lur6mtJbkry8JW8/j1aZwDcdwmiAMwKVbVFkmcmuaLv3zzJp5O8JcnGSV6V5BNVtVlVrZPk6CTPbK2tl+SPkyy+O6/Xh8FDk3y9b/66YT/qfUn+pl/uY5KcPVLGX1fVU1bwHrbsA+3NfXn/uR++Ubpa0u+MTP6dJI+eoFzfHxm+YWvtaf37/UKSjyT5vST7Jvn3qhqb7sZ0QXfDJH+a5CVV9dx+3FNHlrVua+3rK1gtow5IckiS9ZJcvZLXn3SdAcBEBFEAZtrpVfXbJFcl+WWSN/TD/zLJma21M1trd7TWvpBkUZJn9ePvSPKYqlqrtfbz1tp0NWO9Lck2VbV+X3v5rbERrbUNW2uT3lPaWvtpH2g3TfL6JJf1o8bue71+ZPLr04W8qXh2kitba+9vrS3ty/SJJHv1r3tOa+3ifj1dlOS/kuw8xWVP5qTW2qWttaVJ9ljR62cF6wwAJiKIAjDTntvXpO2S5FHpQlzS3Uu5d18L+eu+pvEpSR7cWrsxyV+kq9H8eVV9uqoeNU3leX66sPuTqjq3qna8uwtorV2b5ANJ/qdv7npDP2r9kcnWT/LbKS7yYUmeOG5d7J/k95Okqp5YVV+qqqur6vp062XTyRc3JVdN9fUzDesMgPsWQRSAWaG1dm6Sk5K8sx90VZIP9rWQY3/rtNbe3k//udba05M8OF3N43/2892YZO2RRf9+JtcmKMeFrbU90zVBPT3Jf9/Dt7RGv4z1W2vXJfl5ku1Hxm+fqT+M6Kok545bF+u21l7Sj/9IkjOSPLS1tkG6e19r7C1NsLyprKPR+Vb4+tO4zgC4jxBEAZhN3p3k6VW1IMmHkjynqp5RVfOqas2q2qWqtqiqB1XVn/X3Tv4uXY3j7f0yFid5an+/5gZZ8VN4f5Fki6p6QJJU1QOqav+q2qC1dluS34wsd4Wq6s+r6pFVdb+q2izdz698u68dTZKTk7y+qjbqa2//Ol3wnopPJXlEVR1QVffv/x7fP3Ap6Zr4Xttau6WqnpBkv5F5r07XjPnhI8MWZ+rraIWvf2/WGQD3XYIoALNGa+3qdIHt/7XWrkqyZ5L/L12YuirJq9Odu+6X5B+S/CzJtenuh/zbfhlfSPLRJBcl+Wa6EDWZs9PVSv5fVf2qH3ZAkiur6jfpmrj+5djE/VNnd5pkWZsn+Wy65rYXpwt/zxsZ/4YkP0zykyTnJjmqtfbZFa+RTmvtt0l2T7JP/57/L8k7kjywn+Rvk7ypv9f2iIzUSLbWbkry1iRf65vVPulurqOpvP6k6wwAJlKtTdRiBwAAAFYNNaIAAAAMaqVBtKpOrKpfVtUlk4yvqjq6qq6oqouq6nHTX0wAAADmiqnUiJ6U7vfDJvPMJFv3f4ckOe7eFwsAAIC5aqVBtLX25XQPgpjMnklObp3zk2xYVQ+ergICAAAwt6wxDcvYPMv/6PWSftjPx09YVYekqzXNOuuss8OjHjVdvz0OAADAbPLNb37zV621zSYaNx1BtCYYNuGjeFtrJyQ5IUkWLlzYFi1aNA0vDwAAwGxTVT+ZbNx0PDV3SZKHjvRvke43xgAAAOAupiOInpHkwP7puU9Kcn1r7S7NcgEAACCZQtPcqvqvJLsk2bSqliR5Q5L7J0lr7fgkZyZ5VpIrktyU5IWrqrAAAACs/lYaRFtr+65kfEvy0mkrEQAAAHPadDTNBQAAgCkTRAEAABiUIAoAAMCgBFEAAAAGJYgCAAAwKEEUAACAQQmiAAAADEoQBQAAYFCCKAAAAIMSRAEAABjUGjNdAO6eY19xxUwXYZnDnvvrmS7C8nZeONMluFdm1bZ91x/OdBHulZrpAoxzzGzatvbbaTWr9lvbFoDViBpRAAAABiWIAgAAMChNc1di1jXxm+kCzCG27Qqcu2imS7A8Tfzo2W9h9TPb9ts20wWYQ2zblZhN36dm4XcpNaIAAAAMShAFAABgUIIoAAAAg3KPKAAA9xl+dmkFZuF9hHfHbNq2SXLYc2e6BLObGlEAAAAGJYgCAAAwKEEUAACAQQmiAAAADEoQBQAAYFCCKAAAAIMSRAEAABiUIAoAAMCgBFEAAAAGJYgCAAAwKEEUAACAQQmiAAAADEoQBQAAYFCCKAAAAIMSRAEAABiUIAoAAMCgBFEAAAAGJYgCAAAwKEEUAACAQQmiAAAADEoQBQAAYFCCKAAAAIMSRAEAABiUIAoAAMCgBFEAAAAGJYgCAAAwKEEUAACAQQmiAAAADEoQBQAAYFCCKAAAAINaY6YLAABQM12AcdpMFwBgjlMjCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAY1pSBaVXtU1eVVdUVVHT7B+A2q6pNV9Z2qurSqXjj9RQUAAGAuWGkQrap5Sd6T5JlJtkmyb1VtM26ylyb5bmtt+yS7JPmXqnrANJcVAACAOWAqNaJPSHJFa+1HrbVbk5ySZM9x07Qk61VVJVk3ybVJlk5rSQEAAJgTphJEN09y1Uj/kn7YqGOT/FGSnyW5OMnLW2t3jF9QVR1SVYuqatHVV199D4sMAADA6mwqQbQmGNbG9T8jyeIkD0myIMmxVbX+XWZq7YTW2sLW2sLNNtvsbhYVAACAuWAqQXRJkoeO9G+RruZz1AuTnNo6VyT5cZJHTU8RAQAAmEumEkQvTLJ1Vc3vH0C0T5Izxk3z0yS7JUlVPSjJI5P8aDoLCgAAwNywxsomaK0trarDknwuybwkJ7bWLq2qQ/vxxyd5c5KTquridE15X9Na+9UqLDcAAACrqZUG0SRprZ2Z5Mxxw44f6f5Zkt2nt2gAAADMRVNpmgsAAADTRhAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMao2ZLgAAACtw7qKZLsHydl440yUA5gA1ogAAAAxKEAUAAGBQgigAAACDco8oAMA4x77iipkuwjKHPXemSwAw/dSIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDmlIQrao9quryqrqiqg6fZJpdqmpxVV1aVedObzEBAACYK9ZY2QRVNS/Je5I8PcmSJBdW1Rmtte+OTLNhkn9Pskdr7adV9XurqLwAAACs5qZSI/qEJFe01n7UWrs1ySlJ9hw3zX5JTm2t/TRJWmu/nN5iAgAAMFdMJYhunuSqkf4l/bBRj0iyUVWdU1XfrKoDJ1pQVR1SVYuqatHVV199z0oMAADAam0qQbQmGNbG9a+RZIckf5rkGUn+X1U94i4ztXZCa21ha23hZpttdrcLCwAAwOpvpfeIpqsBfehI/xZJfjbBNL9qrd2Y5Maq+nKS7ZN8f1pKCQAAwJwxlRrRC5NsXVXzq+oBSfZJcsa4af4nyU5VtUZVrZ3kiUm+N71FBQAAYC5YaY1oa21pVR2W5HNJ5iU5sbV2aVUd2o8/vrX2var6bJKLktyR5L2ttUtWZcEBAABYPU2laW5aa2cmOXPcsOPH9R+V5KjpKxoAAABz0VSa5gIAAMC0EUQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABiWIAgAAMChBFAAAgEEJogAAAAxKEAUAAGBQgigAAACDEkQBAAAYlCAKAADAoARRAAAABjWlIFpVe1TV5VV1RVUdvoLpHl9Vt1fVXtNXRAAAAOaSlQbRqpqX5D1JnplkmyT7VtU2k0z3jiSfm+5CAgAAMHdMpUb0CUmuaK39qLV2a5JTkuw5wXR/l+QTSX45jeUDAABgjplKEN08yVUj/Uv6YctU1eZJnpfk+BUtqKoOqapFVbXo6quvvrtlBQAAYA6YShCtCYa1cf3vTvKa1trtK1pQa+2E1trC1trCzTbbbIpFBAAAYC5ZYwrTLEny0JH+LZL8bNw0C5OcUlVJsmmSZ1XV0tba6dNRSAAAAOaOqQTRC5NsXVXzk/xvkn2S7Dc6QWtt/lh3VZ2U5FNCKAAAABNZaRBtrS2tqsPSPQ13XpITW2uXVtWh/fgV3hcKAAAAo6ZSI5rW2plJzhw3bMIA2lo7+N4XCwAAgLlqKg8rAgAAgGkjiAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBTSmIVtUeVXV5VV1RVYdPMH7/qrqo/zuvqraf/qICAAAwF6w0iFbVvCTvSfLMJNsk2beqthk32Y+T7Nxa2y7Jm5OcMN0FBQAAYG6YSo3oE5Jc0Vr7UWvt1iSnJNlzdILW2nmttev63vOTbDG9xQQAAGCumEoQ3TzJVSP9S/phk3lRks9MNKKqDqmqRVW16Oqrr556KQEAAJgzphJEa4JhbcIJq3ZNF0RfM9H41toJrbWFrbWFm2222dRLCQAAwJyxxhSmWZLkoSP9WyT52fiJqmq7JO9N8szW2jXTUzwAAADmmqnUiF6YZOuqml9VD0iyT5IzRieoqi2TnJrkgNba96e/mAAAAMwVK60Rba0trarDknwuybwkJ7bWLq2qQ/vxxyc5IskmSf69qpJkaWtt4aorNgAAAKurqTTNTWvtzCRnjht2/Ej3i5O8eHqLBgAAwFw0laa5AAAAMG0EUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKAEUQAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAgxJEAQAAGJQgCgAAwKDWmOkCjLrtttuyZMmS3HLLLTNdlGU+M9MFGGfjvW6bcHhLctN198vlX31Alv7O9QUAAGD2mlVBdMmSJVlvvfWy1VZbpapmujhJkhtnugDjbHnVxCG9tZYbNrkuybW59ItrDlsoAACAu2FWVZ3dcsst2WSTTWZNCF2dVFXWXXujrL3RHTNdFAAAgBWaVUE0iRB6L1RVrD0AAGC2m3VBFAAAgLltVgfRmua/qZg3b14WLFiQxzzmMdl7771zy0033ev3cfwRR+SCs86adPwnjj8+nz755Hv9OgAAAKuDWfWwotlgrbXWyuLFi5Mk+++/fz5x/PHZ/5WvXDb+9ttvz7x58+7WMg9905tWOP75hx56t8sJAACwuprVNaIzbaeddspVV1yRb55zTg7ddde8fr/9su+22+b222/Pv7361Tnw8Y/Pvtttl1P/4z+WzXPyP/9z9tl22+y3/fY55vDDkyRHHnxwvvjxjydJjjn88Lxgm22y73bb5d2velWS5IQjj8wH3/nOJMnlixfnhU96Uvbdbru8+nnPy2+uuy5J8je77JJjXvOaPOM5T8mOO2+b8y/46pCrAgAAYNqoEZ3E0qVL85nPfCZ/tMceSZJLv/GNnHLJJdl8/vycesIJWXeDDXLyhRfm1t/9Li9+8pPzxN13z5WXXZZzTj89J11wQdZce+1cf+21yy3z+muvzTmnnZaPX3ZZqiq//fWv7/K6Rx54YF51zDHZYeedc/wRR+Q/3/jG/MO7372sTJ/75Fdz1tmfzTvf/bZ8/L/OXNWrAQAAYNqpER3n5ptvzoIFC7Jw4cJsueWW2fNFL0qSPPoJT8jm8+cnSS74/Odz5sknZ78FC3LwE5+Y66+5Jlf94Af5xlln5TkvfGHWXHvtJMkGG2+83LLXWX/9PHDNNfOWF784Z5966rLpxtxw/fX57a9/nR123jlJ8uyDDsq3v/zlZeOf9ud/niTZbtvH5qolP1k1KwAAAGAVUyM6zug9okmyaGz4OussG9Zay6uOOSY7PuMZy8379c9+doU/P7PGGmvkpG98Ixd+8Yv5/Cmn5GPHHpvjzj57ymW7/wMfmKR7oNLtty+d8nwAAACziRrRe+BJz3hGPnHccVl6221Jkp98//u5+cYb88Tdd88ZJ5647Em745vm3nTDDbnh+uvz5Gc9K69897vz/ZHAmyTrbrBB1t9oo3z7K19Jkpz5wQ/mcX3tKAAAwFwxq2tE20wXYBLPffGL8/Mrr8xfPu5xaa1lo802yztPPz1/vMce+f7ixTlw4cKs8YAH5MnPelZe+ra3LZvvpt/+Nv+w55659ZZb0lrLK971rrss+w0f+EDefuihueWmm7L5wx+eI97//iHfGgAAwCo3q4PoTLjhhhvuMmyHXXbJDrvssqz/fve7X176trctFzLHHHz44Tm4f1rumCNPOmlZ9we+8Y27zHPIkUcu637kggV5//nn32Wa/zjnnK7jqluyycabZtF5l6/4jQAAAMxSmuYCAAAwKEEUAACAQQmiAAAADEoQBQAAYFCCKAAAAIMSRAEAABjUrP75lmNfccW0Lu+wd/3hSqeZN29ett122yxdujTz58/PKz/4way34YbTVoY/22qrnLxoUTbcdNM8dd118+UJfi4GAABgLlMjOs5aa62VxYsX55JLLsnGG2+cj73nPTNdJAAAgDlFEF2BHXfcMb/83/9Nkiz54Q/zd3vskQN22CF/vdNOufKyy5Ik1/ziF3n1856X/bbfPvttv32+c955SZJXPfe5OWCHHfKCRz86p55wwoy9BwAAgNlmVjfNnUm33357vvjFL+apL3pRkuSthxyS1x5/fLbceutccsEFecff/m2OO/vsvPNlL8tjd945R512Wm6//fbc3De1/X8nnpgNNt44t9x8cw56/OPztOc/PxtusslMviUAAIBZQRAd5+abb86CBQty5ZVXZocddsgTn/703HTDDbn4vPNy+N57L5vutt/9Lkmy6Oyz88aTT07S3V+67gYbJEk+evTROee005Ikv7jqqlz1gx8IogAAABFE72LsHtHrr78+z372s/Ox97wnzz744Ky74Yb5yOLFU1rGN885J98466yc+PWvZ821187f7LJLbr3lllVbcAAAgNWEe0QnscEGG+Too4/Oh975zqy51lp5yPz5OetjH0uStNby/e98J0ny+N12y8ePOy5J15z3ht/8Jjdcf33W22ijrLn22rnysstyyfnnz9j7AAAAmG1mdY3oVH5uZVV67GMfm6233z6fP+WUvPnDH87bX/KSnPiWt2Tpbbfl6fvsk0dsv33+4d/+LW875JCc8b735X7z5uXw447LjnvskU8cf3z23W67POyRj8xjnvSkGX0fAAAAs8msDqIz4YZxv+v5rk9+cln3MZ/97F2m3+RBD8q//M//3GX40Z/5zITLP+PKK5d1+w1RAADgvkjTXAAAAAYliAIAADAoQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAg5rdP99y7qLpXd7OC1c6ybx587Ltttsu63/T6adn7fXWy+F77ZXvXnhhnn3wwfnHY4+d3nIBAADch8zuIDoD1lprrSxevHhZ/6IkN994Yw5985vzw0suyQ8vuWSwsixdujRrrGETAQAAc4umuVOw1jrrZMFTnpIHrLnmCqf74aWX5qAnPCH7LViQfbfbLj/9wQ+SJJ8++eTsu9122W/77XPEAQckSX7+k5/kJbvtln232y4v2W23/N9Pf5okOfLgg/OuV74yh+66a455zWuy5Ic/zN/tsUcO2GGH/PVOO+UHV1y+at8sAADAKqa6bZybb745CxYsSJLMnz8/rzvttCnPe+rxx2efl788z9x//9x26625/fbb88NLL82Jb31r3ve1r2XDTTfN9ddemyT558MOy58eeGCefdBBOePEE/POl70s7zz99CTJT7///bznrLMyb968vGS33fLa44/PlltvnUsuuCCveeXLc+opn53utw0AADAYQXSciZrmTtW2O+6YE9/61vxyyZLs+ud/ni233jqLzj47u+21VzbcdNMkyQYbb5wkufjrX89Rp56aJHnWAQfk6H/8x2XL2W3vvTNv3rzcdMMNufi883L43nvf+SI33nKP3xsAAMBsIIjeC1867bT85xvfmCR5/Xvfmz322y+PeeIT89VPfzp/94xn5PXvfW9aa6mqlS5rdJq11lknSXLHHXdk3Q03zEdGgvGWVwmiAADA6s09ovfCrs97Xj6yeHE+snhxtlm4MEt+9KNs/vCHZ5+XvSxP/bM/yw8uuiiP3223nPXf/51fX3NNkixrmrvdH/9xPn/KKUmSz3z4w1nwlKfcZfnrrr9+HjJ/fs762MeSJK21XPrdiwZ6dwAAAKvG7K4RncLPrQzlz7baKjf+5je57dZbc+7pp+eYz38+D99mm+Wm+cJHP5rPfOhDWeP+988mv//7efERR2SDjTfOC1/3uvzNzjtn3rx5ecRjH5sjTzoprzr66Lz5r/4qHzzqqGy42WZ5w/vfP+HrvvnDH87bX/KSnPiWt2Tpbbdl72fulUdvs90QbxkAAGCVmN1BdAbccMMNEw4/48orVzrvC1/72rzwta+9y/BnH3RQnn3QQcsNe8hWW+W4s8++y7RHnnTScv2bz5+fYz5758OJNM0FAABWd5rmAgAAMChBFAAAgEHNuiDaWpvpIqy2Wmux9gAAgNluVgXRNddcM9dcc40weg+01nLDTdflputm1SYFAAC4i1n1sKItttgiS5YsydVXXz3TRVnmVzNdgHHuuPa2CYe3JDddd79c/tUHDFsgAACAu2lWBdH73//+mT9//kwXYznbrHySQR3ziitmuggAAAD3ypTacVbVHlV1eVVdUVWHTzC+qurofvxFVfW46S8qAAAAc8FKg2hVzUvyniTPTFdBuG9Vja8ofGaSrfu/Q5IcN83lBAAAYI6YSo3oE5Jc0Vr7UWvt1iSnJNlz3DR7Jjm5dc5PsmFVPXiaywoAAMAcUCt7Qm1V7ZVkj9bai/v+A5I8sbV22Mg0n0ry9tbaV/v+LyZ5TWtt0bhlHZKuxjRJHpnk8ul6I9wtm2b2PYeJ6WHbzm2279xl285dtu3cZdvOXbbt9HlYa22ziUZM5WFFNcGw8el1KtOktXZCkhOm8JqsQlW1qLW2cKbLwfSzbec223fusm3nLtt27rJt5y7bdhhTaZq7JMlDR/q3SPKzezANAAAATCmIXphk66qaX1UPSLJPkjPGTXNGkgP7p+c+Kcn1rbWfT3NZAQAAmANW2jS3tba0qg5L8rkk85Kc2Fq7tKoO7ccfn+TMJM9KckWSm5K8cNUVmWmgefTcZdvObbbv3GXbzl227dxl285dtu0AVvqwIgAAAJhOU2maCwAAANNGEAUAAGBQgui9VFU3TMMyFlbV0SsYv1VV7TfV6ftprqyqi6vqoqo6t6oedm/LOV2q6tCqOnCmyzGdqupBVfWRqvpRVX2zqr5eVc+7F8s7sqpe1Xe/qar+5B4uZ0FVPWuk/+CqurqqFlfVpVX18apa+56Wc2Wvtzqrqtv79XRJVX2yqjacpuUeXFXHTseyxi33nKq6vC/z4v43oKfd+OMRK1ZVr+v3tYv67fKZqvqncdMsqKrv9d1XVtVXxo1fXFWXDFnumTKy311aVd+pqldW1Sr9rlJVJ1XV/1bVA/v+TavqylX5mv3rTHgs6IffUVXbjQy7pKq2Wsny/n46j+cjyz2nqu5zP2NRVc+rqlZVj+r7t+r7/25kmmOr6uC+e0Y+R6u7qtqiqv6nqn5QVT+sqn/rH466onk2rKq/Hel/SFV9/G6+7j3+bjVuORPmgBUdy6pql/6z9JyR6T9VVbv03edU1aKRcQur6px7W9bZSBCdBVpri1prL1vBJFslWfbFbwrTj9m1tbZdknOSvP5eFTJJde71Z6a1dnxr7eR7u5zZoqoqyelJvtxae3hrbYd0T5feYtx0U/nd3rtorR3RWjvrHhZvQboHiY36aGttQWvt0UluTfIX93DZU3291dXN/Xp6TJJrk7x0pgs0Bfv3ZV7QWpvSSfkefC63ysjxiMlV1Y5Jnp3kcf2x+E+SvD133ef2SfKRkf71quqh/TL+aIiyziI3jxyfnp7uePKGAV739iR/Nd0LvafH/XQ/i/e6uznP3yeZ1iBaVfOmc3mrmX2TfDXd/jnml0levoKgtEo+R3NV//3p1CSnt9a2TvKIJOsmeetKZt0wybIg2lr7WWvtbl18vZffraZiZceyle3jv1dVz1yF5ZsVBNFVoL+6fX5/Bfy0qtqoH/74ftjXq+qosSvc/ZWRT/XdO4/UaHy7qtZL98Vlp37YK8ZNv25Vvb/urP18/gRF+nqSzfvpN6uqT1TVhf3fk0eGf6GqvlVV/1FVP+mv5m1VVd+rqn9P8q0kD62qV/fzXlRVb+znX6eqPt1f9bmkqv6iH/72qvpuP+07+2GjtX2TratzquodVfWNqvp+Ve20arbWtHhaklv7J0gnSVprP2mtHVPdle2PVdUnk3y+315f7NfzxVW159g81dWcXF5VZyV55Mjwk6qv3aqqHaqr4f5mVX2uqh7cD7/L+upPlG9K8hf9Z2e5L7/9F6R1klzX9z+sL9tF/f8tVzJ8735bf6eqvryy11vNje5DT6iq8/r987yqemQ//OCqOrWqPlvdld1/Hpu5ql7Yb5dzkzx5ZPhk6/akqjquqr5UXS37zlV1Yr8vnjTVQlfVxlV1er/886uvYen3wROq6vNJTl7BcWGlx6N7u2LnuAcn+VVr7XdJ0lr7VWvt3CS/rqonjkz3giSnjPT/d+4Mq/sm+a8hCjvbtNZ+meSQJIdVZ151586x88/fjE1bE5+Xtqqqy6rqA/3wFbUAeXeSV9QEwXEFy75kZJpXVdWRffc5VfW2fn9/eVU9p6ou6Pehs6rqQVN4+59K8uix48u48uxe3feIb1V3flm3ql6W5CFJvtQfN15QVf/aT//yqvpR3/0HVfXVvnu3vkwX98eXsZq8K6vqiH66vUde9379unzLFMq/WquqddMdq1+U5YPo1Um+mOSgSWZ9dyb5HDGhpyW5pbX2/iRprd2e5BVJ/qqq1u7Pq//Tn1cvr6qxIPf2JH/Qn4eOGt0f+3lOr64l04+r6rDqaiO/3Z8HN+6nO6mq9qqutnHsPHdxVbV+/B/0r/vNqvpK3VkzPr/f/y6sqjdP5U2OP5b1g7+T5Pqqevoksx2VaahEmvVaa/7uxV+SGyYYdlGSnfvuNyV5d999SZI/7rvfnuSSvnuXJJ/quz+Z5Ml997rpfmJn2fgJpn/H2PL7/o36/1cm2bTvfneSQ/rujyR5St+9ZZLv9d3HJnlt371HkpZk03S1H3ckeVI/bvd0j7SudBcyPpXkqUmen+Q/R8qxQZKNk1yeO5/OvGH//8gkr1rJujonyb/03c9KctZMb+sVfAZeluRdk4w7ON1Vr437/jWSrN93b5ruJ48qyQ5JLk53NXv9fvjYOjopyV5J7p/kvCSb9cP/It3PKU26vvrXP3Zcea5OsjjJL5J8Jcm8kc/eQX33X6W7Qrmi4Rcn2Xzctl3u9Vbnv/T7drqfrfpYkj36/vWTrNF3/0mST4y89x/1n/01k/wkyUPThZGfJtksyQOSfG1sHa1g3Z6ULphUkj2T/CbJtun2uW8mWTBBec9Jt78t7v82SXJMkjf045+WZHG7cx/8ZpK1+v7JjgsrPR75W+FnaN1+W3w/yb/nzmPdq9MfM5I8KcmFI/Ncma5W4Ly+/9tJtkl/vpjrf5n4nHpdkgel+yL3+n7YA5MsSjI/k5+Xtkp3Lhv7DJ+Y/rg6bvknpTvGnpju5+c2TXJlP25Fy75kZBmvSnJk331Okn8fGbdR7jwPvjh3HqsPzgTHy7HhSQ5M8oF+2CX9a26a5MtJ1umHvybJESOfnbHz/u+Pfa6SfDzdb8Jvni5A/VO6Y9RVSR7RT3Nykr8fWc4/jpTnnP5z+l9JXjfTn5GBPod/meR9ffd5SR43ts37z9xl6c4NxyY5eGWfI3+TrucJvz+lO+5t1+8LP093PlurX/8LJ9j/lvX381yRZL10593rkxzaj3vXyOf8pCR7jXvdo5Ic1Xd/McnWffcTk5zdd5+R5MC++6WZ4JjVj1vRsWyXdMeSnZKc24/7VJJd+u5z+vd5dpJd++5zZnp7rYo/NaLTrKo2SPel/Nx+0AeSPLW6+8vWa62d1w//yETzp/uS+q/91c0NW2tLV/KSf5LkPWM9rbXrRsZ9qap+2U/zkZHpj62qxel2pvX7Wo6npL8i31r7bPpast5PWmvn992793/fTldD+qgkW6cLJX9SXa3cTq2169N9eb4lyXur6s/T/cbsMpOtq5FJTu3/fzPdQWa1UFXvqa6W8MJ+0Bdaa9eOjU7ytqq6KMlZ6b4YPCjdwei01tpNrbXfpNs24z0yyWOSfKHffq/P8s1/p7q+PtpaW5Dui8rF6b4UJ8mOufNz8sF0n4kVDf9akpOq6q/TnZDnmrX69XxNuosqX+iHb5DkY/3V13clefTIPF9srV3fWrslyXeTPCzdCeyc1trVrbVbk3x0ZPrJ1m2SfLJ1Z6SLk/yitXZxa+2OJJdm8u072jT3mn55H0yS1trZSTbp97skOaO1dnPfPdlx4e4ejxjRWrsh3UWmQ9JdAPpodfeTnZJkr+puddgnd63xvDbJdVW1T5LvZdyx8z5orAZh9yQH9p/TC9J9Od06k5+XkuSq1trX+u4PZfl9bLy3pTsejn43WtGyV2R0P98iyeeqaux4++iJZ7mLjyR5UlXNHxn2pHQXJr7Wr4eD0h1nltNa+78k6/b78UP7ZT013bnmK+nOJz9urX2/n2X8+Xe0/EnyH+m+6K+syeRcsW/ubKVwSt+fJGmt/TjJNzL5LQoTfY6YWKW7WLSi4V9orV3Tn69OzYr34TFfaq39trV2dbog+sl++MWZ5PxZVS9Id8Hh8L5G/I/TnesXp/v8P7if9Mm585j9wSmUZbmXGe1prX2lf+3JWv29JXO8VtROMpxa+SRJa+3t6a6YrpXk/LGmACtZ7kQ7cdJdRXlYui+ub+qH3S/JjiNfVjdvrf12JeW7cdzr/dPI/H/YWntffzIbq9X7p6o6ov/S+oQkn0jy3CSfXcl7Ge93/f/b09XEzFaXpjt4JUlaay9Nslu6K3HJ8utv/374Dn0Y/EW6K9PJ5NtxTCW5dGTdb9ta231k/N1aX33I+WSW//Kx3CQrGt5aOzTdAfKhSRZX1SYre83VzM39NnpYuprMsXtE35zuJPeYJM/JndsvuXMbJMtvh5Vt2zGj040t645xy70jU98fJtqvx15j9HM54XHhHhyPGKe1dntr7ZzW2huSHJbk+a21q9LVOu2crjXJf08w60fTXWS8TzbLHVNVD0+3L/0y3ef570Y+p/Nba5/PJOelfhHj971J98XW2hXparBfMFqESZa9NMt/hxo9DiTL71/HpKv53DbJ30ww7WTlWZrkX9LVeo6W5wsj5dmmtfaiSRbx9XQ1c5enC587pbv49bWs/DvJjeP6z0uya1VNqeyrs/5c9rR0F9GvTBcq/yLLr7O3pdsud/kePcnniIldmq62b5mqWj/d94of9oOmvA+PGH/OHD2fTtT8/tFJ3phkn9Y1D75fkl+P7GcLWmuj9+tP9Zw++hqjx7JRb80k94r2F5DXTHcBak4SRKdZXxN43cjVjQPSVbtfl+S3VTX2Ydpnovmr6g/6mo93pGt29Kgkv03XxGAin0/35WZs/o3GlefmdA8wOLBvFz9++gV951fTHzSravd0TYkm8rl0bffX7afdvKp+r6oekuSm1tqHkrwzyeP6aTZorZ3Zl2HB6IImW1eTvO5sdnaSNavqJSPDJrsPaYMkv2yt3VZVYxcKkq6p1fOqaq3+CvZzJpj38iSbVfcAlFTV/fuD54qs6LOTdFcWxw725+XOz+X+6T4Tkw7vP6sXtNaOSPKrdCeOlb3eaqf/nL4syauq6v7ptuH/9qMPnsIiLkiyS1Vt0s+/98i4ydb5dPlyv9xU9zS+X/U17uNNeFy4B8cjRlTVI6tqtPZsQbom20kXMN+V5IettSUTzH5akn9Od8y9T6qqzZIcny7EtXTr4iX9fpSqekRVrZNJzkv9YrYcO2bmzofPrMhb0zWzHTPZsn+R7mEim1R3b+WzV7DM0WPGQSt948s7KV2LhbELm+cneXJV/WFfnrWr6hH9uPH75pf79/LldDW6uyb5XX9MuyzJVmPLycrPv+9Lcma6GqLZfGF4OuyV5OTW2sNaa1u11h6a5McZaYHUWrssXauXybb7+M8RE/tikrWr/yWF6h6O9S9JTmqtjbUEeXp1zztYK12lxtcyjeehvpXQKema216dJP158sdVtXc/TVXV9v0sX8vy5+2pvMb4Y9ky/cW0jZJsP9G86T5L/zj1d7R6EUTvvbWrasnI3yvTnWiO6ptfLsidtZEvSnJCVX093ZW16ydY3t9X/wCYJDcn+Uy6+yiX9s09xz8c5C1JNhqZZ9fxC2yt/Tzdl56XpvtCvbC6hy58N8mh/WRvTLJ7VX0ryTPTtcn/7QTL+ny6Jj5f75sZfTzdwWDbJN/omzC8ri/Xekk+1a+Hc9PdgD7eZOtqtdEfVJ6bZOfqboz/RrpmTq+ZYPIPp1v/i9IdwC7rl/GtdDUgi9PVIH9l/Ix9s869kryj39aL0zUdWZEvJdmmln940NjDhC5K8th0NXxJ99l4YT/8gCQvX8nwo6q7sf+SdF90vjPJ6632WmvfTvf+9kkXDv6pqr6WKTRJ7ve/I9PVTpyVrnnfmMnW7XQ5Mv3+nu6+9Mm+BE92XLi7xyOWt26SD1T/wLZ0TSqP7Md9LF0TzVMmmrGvkX5Hv9/fl6zVHz8uTbe/fD7d+SlJ3pvuy/+3+uPOf6S7X3uy81LSNW0+qF//Gyc5bkUv3lq7NCP76GTLbq3dlu58dUG6e7suW8Fij0wX4L6S7qLdlPXb/+gkv9f3X53uAth/9e/p/HQXiJLuXtbPVNWX+v6vpLtA+OW+lueq9EG8dbcPvLAv18XpaoqWPXBvkrL8a7p188FaxT+pM8P2TXchaNQnkvx/44a9NeOejj9m/OeIifXfn56XZO+q+kG6++lvyfLr+qvpmsAuTvdMhkWtu/Xka/356ah7WYznpqsU+M/+2LO4H75/khf1579L0z2vIenO0y+t7varDTK5FR3LxlvRZ+nMdLd2zEk1LpizClXVuq27ZyhVdXiSB7fWpvuL5z3SX9G9vbW2tL96fFzfLBEAVjvV/e7mp/pm9MBqprp76he21g5b2bSsnuZ684rZ5k+r6rXp1vtPMrVmfUPZMsl/91c5b03y1zNcHgAAYI5SIwoAAMCg5nIbfwAAAGYhQRQAAIBBCaIAAAAMShAFAABgUIIoAAAAg/r/AWyHyxjFq1WgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = np.arange(7)\n",
    "# Set position of bar on X axis\n",
    "barWidth=0.3\n",
    "r1 = np.arange(len(totalPrecision))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "\n",
    "plt.subplots(figsize=(16, 7))\n",
    "plt.bar(r1,totalPrecision,width=barWidth, label='Precision', color=\"cyan\")\n",
    "plt.bar(r2,totalRecall,width=barWidth, label='Recall', color=\"mediumpurple\")\n",
    "plt.bar(r3,totalF,width=barWidth,  label='F1-score', color=\"pink\")\n",
    "plt.axis([-0.5,7,0, 1])\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Results: 30 features')\n",
    "\n",
    "# Add xticks on the middle of the group bars\n",
    "plt.xticks([r + barWidth for r in range(len(totalPrecision))], names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "3c92021a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.patches as mpatches\n",
    "rects=[]\n",
    "rects.append(mpatches.Patch(color='blue', label='Precision'))\n",
    "rects.append(mpatches.Patch(color='orange', label='Recall'))\n",
    "rects.append(mpatches.Patch(color='green', label='F1 Score'))\n",
    "\n",
    "plt.subplots(figsize=(10, 5))\n",
    "plt.plot(names,totalResults)\n",
    "plt.legend(handles=rects);\n",
    "plt.title('Results: 30 features');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592aaf11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
